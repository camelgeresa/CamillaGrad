{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'arr_padded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m unpadded_array \u001b[38;5;241m=\u001b[39m arr_padded\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(arr_padded\u001b[38;5;241m.\u001b[39mndim):\n\u001b[0;32m      3\u001b[0m     length \u001b[38;5;241m=\u001b[39m arr_padded\u001b[38;5;241m.\u001b[39mshape[i]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'arr_padded' is not defined"
     ]
    }
   ],
   "source": [
    "unpadded_array = arr_padded\n",
    "for i in range(arr_padded.ndim):\n",
    "    length = arr_padded.shape[i]\n",
    "    slices = [slice(None, None,None)]*arr_padded.ndim\n",
    "    slices[i] = slice(2,length-2,None)\n",
    "    unpadded_array =unpadded_array[tuple(slices)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.        ,  0.        , -0.29455742, -0.97127459,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.        ,  0.        , -0.05102565, -0.98312818,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "random_arr = np.random.randn(2,2)\n",
    "np.pad(random_arr, ((2,2),(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tensor import Tensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor(np.array([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Tensor(np.array([4,5,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(data = [[1]\n",
       " [2]\n",
       " [3]], grad = 0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape((3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "def get_user_attributes(cls):\n",
    "    boring = dir(type('dummy', (object,), {}))\n",
    "    return [item\n",
    "            for item in inspect.getmembers(cls)\n",
    "            if item[0] not in boring]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.transpose().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pad(random_arr, (2,2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 2, 1, 1, 1],\n",
       "       [1, 1, 1, 2, 1, 1, 1],\n",
       "       [1, 1, 1, 2, 1, 1, 1],\n",
       "       [1, 1, 1, 2, 1, 1, 1],\n",
       "       [3, 3, 3, 4, 3, 3, 3],\n",
       "       [1, 1, 1, 2, 1, 1, 1],\n",
       "       [1, 1, 1, 2, 1, 1, 1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pad(arr, ((3, 2), (2, 3)), 'minimum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 2, 1, 1, 1],\n",
       "       [1, 1, 1, 2, 1, 1, 1],\n",
       "       [1, 1, 1, 2, 1, 1, 1],\n",
       "       [1, 1, 1, 2, 1, 1, 1],\n",
       "       [3, 3, 3, 4, 3, 3, 3],\n",
       "       [1, 1, 1, 2, 1, 1, 1],\n",
       "       [1, 1, 1, 2, 1, 1, 1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[1, 2], [3, 4]]\n",
    "np.pad(a, ((3, 2), (2, 3)), 'minimum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 6, 4],\n",
       "       [8, 5, 3]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpadded_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    r\"\"\"Transform 4 dimensional images to 2 dimensional array.\n",
    "    From stanford university cs231n assignment 2.\n",
    "    More [here](http://cs231n.stanford.edu/).\n",
    "\n",
    "    Args:\n",
    "        input_data (Tensor): 4 dimensional input images (The number of images, The number of channels, Height, Widht)\n",
    "        filter_h (int): height of filter\n",
    "        filter_w (int): width of fitter\n",
    "        stride (int): the interval of stride\n",
    "        pad (int): the interval of padding\n",
    "\n",
    "    Returns:\n",
    "        col (Tensor): 2 dimnesional tensor\n",
    "\n",
    "    .. warning::\n",
    "\n",
    "        This function is not compatible with ``autograd``system. The resulting ``Tensor`` has no links to a\n",
    "        previous computational graph, and in addition its gradient is set to ``None``.\n",
    "\n",
    "    \"\"\"\n",
    "    # Extract the shape from one's image\n",
    "    N, C, H, W = input_data.shape\n",
    "\n",
    "    # Make sure that the convolution can be executed\n",
    "    # TODO: replace by a warning\n",
    "    assert (H + 2 * pad - filter_h) % stride == 0, f'invalid parameters, (H + 2 * pad - filter_h) % stride != 0, got ' \\\n",
    "                                                   f'H={H}, pad={pad}, filter_h={filter_h}, stride={stride}'\n",
    "    assert (W + 2 * pad - filter_w) % stride == 0, f'invalid parameters, (W + 2 * pad - filter_w) % stride != 0, got ' \\\n",
    "                                                   f'W={W}, pad={pad}, filter_w={filter_w}, stride={stride}'\n",
    "    # Initialize the output dimensions\n",
    "    out_h = (H + 2 * pad - filter_h) // stride + 1\n",
    "    out_w = (W + 2 * pad - filter_w) // stride + 1\n",
    "    # Pad the input data\n",
    "    padding = ((0, 0), (0, 0), (pad, pad), (pad, pad))\n",
    "    image = nets.pad(input_data, padding)\n",
    "    # Initialize the output\n",
    "    col = nets.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    # For loops...\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride * out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride * out_w\n",
    "            col[:, :, y, x, :, :] = image[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N * out_h * out_w, -1)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array([[[1,2,3],[4,5,6]],[[2,3,4],[5,6,7]],[[3,4,5],[6,7,8]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 6.58989223e-01 -2.60027883e-01  1.23237399e+00  1.23346458e+00]\n",
      "   [-2.52429466e-01 -1.10845956e+00  1.84329960e+00 -1.65008438e+00]\n",
      "   [-1.37388900e+00 -3.93228742e-02  1.49524951e-01  5.54141876e-01]\n",
      "   [ 1.57419656e+00 -7.04228633e-01 -2.67698344e-02 -5.52936092e-02]]\n",
      "\n",
      "  [[ 9.61757196e-01  6.54402912e-01  1.20023782e-01 -6.86277409e-01]\n",
      "   [-3.06907256e-01  2.37223259e-01  6.91925977e-01 -1.63771426e+00]\n",
      "   [-1.56311000e+00 -2.21949531e-01 -2.05308977e-01  1.17524740e+00]\n",
      "   [-1.26745183e-01 -5.11528587e-01  2.16780390e-01 -2.19178336e-01]]\n",
      "\n",
      "  [[ 1.30081129e+00  2.12125247e-01 -1.36801144e+00  9.77561881e-01]\n",
      "   [-5.98144146e-02  8.28596780e-01  5.38645926e-01  1.38645951e-01]\n",
      "   [-5.82173268e-01  1.45732433e-01  8.76600465e-01 -9.09821224e-01]\n",
      "   [-1.16022845e-01  1.39945545e+00 -7.51955452e-01 -1.72473698e-01]]]\n",
      "\n",
      "\n",
      " [[[-4.71853569e-01 -1.05629618e+00  3.17709774e-01 -3.78260448e-01]\n",
      "   [ 1.77857612e+00 -2.48681075e-01  2.00759241e+00  1.85364706e-03]\n",
      "   [ 6.30990277e-01  1.59858283e+00 -1.13712626e+00 -2.40478590e+00]\n",
      "   [ 5.09214342e-01  6.83248586e-01 -1.91458164e+00  9.57784405e-01]]\n",
      "\n",
      "  [[ 8.76387200e-01  2.63921840e-01  2.16770236e-01  2.69205205e-02]\n",
      "   [-1.09560144e+00  5.93410593e-01  1.47906806e+00 -1.52329378e-01]\n",
      "   [ 6.75389555e-01 -5.31742131e-01 -5.66813896e-01  3.05534490e-01]\n",
      "   [-9.13047685e-01  9.11744955e-01  9.36197669e-01 -1.76387823e+00]]\n",
      "\n",
      "  [[-1.87602600e+00 -6.83646635e-01  9.21935071e-01  7.95657126e-01]\n",
      "   [-1.81510213e+00 -9.13072332e-01  3.08852821e-01  2.44860192e-01]\n",
      "   [-2.69297175e-01 -9.52156432e-01 -4.14413232e-01  1.43927238e-01]\n",
      "   [ 4.59360016e-01  2.67462247e-01  4.89436657e-01 -4.58183657e-01]]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "N = 2 # 2 images\n",
    "C = 3\n",
    "H = 4\n",
    "W = 4\n",
    "filter_h = 2\n",
    "filter_w = 2\n",
    "stride = 1\n",
    "image = np.random.randn(N,C,H,W)\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_h = (H  - filter_h) // stride + 1\n",
    "out_w = (W  - filter_w) // stride + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_case = np.randn((N, C, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why not \n",
    "col2 = np.zeros((N,C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "for i in range(out_h):\n",
    "    for j in range(out_w):\n",
    "        # populating each kernel, each SLIDE, 1 slide along each direction\n",
    "        # (filter_h x filter_w) corresponds to the num of entries, size of the kernel\n",
    "\n",
    "        # get all the elements:\n",
    "        image[col2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_max=3,x_max = 3, [[[[ 0.65898922 -0.26002788  1.23237399]\n",
      "   [-0.25242947 -1.10845956  1.8432996 ]\n",
      "   [-1.373889   -0.03932287  0.14952495]]\n",
      "\n",
      "  [[ 0.9617572   0.65440291  0.12002378]\n",
      "   [-0.30690726  0.23722326  0.69192598]\n",
      "   [-1.56311    -0.22194953 -0.20530898]]\n",
      "\n",
      "  [[ 1.30081129  0.21212525 -1.36801144]\n",
      "   [-0.05981441  0.82859678  0.53864593]\n",
      "   [-0.58217327  0.14573243  0.87660047]]]\n",
      "\n",
      "\n",
      " [[[-0.47185357 -1.05629618  0.31770977]\n",
      "   [ 1.77857612 -0.24868108  2.00759241]\n",
      "   [ 0.63099028  1.59858283 -1.13712626]]\n",
      "\n",
      "  [[ 0.8763872   0.26392184  0.21677024]\n",
      "   [-1.09560144  0.59341059  1.47906806]\n",
      "   [ 0.67538955 -0.53174213 -0.5668139 ]]\n",
      "\n",
      "  [[-1.876026   -0.68364663  0.92193507]\n",
      "   [-1.81510213 -0.91307233  0.30885282]\n",
      "   [-0.26929717 -0.95215643 -0.41441323]]]]\n",
      "y_max=3,x_max = 4, [[[[-2.60027883e-01  1.23237399e+00  1.23346458e+00]\n",
      "   [-1.10845956e+00  1.84329960e+00 -1.65008438e+00]\n",
      "   [-3.93228742e-02  1.49524951e-01  5.54141876e-01]]\n",
      "\n",
      "  [[ 6.54402912e-01  1.20023782e-01 -6.86277409e-01]\n",
      "   [ 2.37223259e-01  6.91925977e-01 -1.63771426e+00]\n",
      "   [-2.21949531e-01 -2.05308977e-01  1.17524740e+00]]\n",
      "\n",
      "  [[ 2.12125247e-01 -1.36801144e+00  9.77561881e-01]\n",
      "   [ 8.28596780e-01  5.38645926e-01  1.38645951e-01]\n",
      "   [ 1.45732433e-01  8.76600465e-01 -9.09821224e-01]]]\n",
      "\n",
      "\n",
      " [[[-1.05629618e+00  3.17709774e-01 -3.78260448e-01]\n",
      "   [-2.48681075e-01  2.00759241e+00  1.85364706e-03]\n",
      "   [ 1.59858283e+00 -1.13712626e+00 -2.40478590e+00]]\n",
      "\n",
      "  [[ 2.63921840e-01  2.16770236e-01  2.69205205e-02]\n",
      "   [ 5.93410593e-01  1.47906806e+00 -1.52329378e-01]\n",
      "   [-5.31742131e-01 -5.66813896e-01  3.05534490e-01]]\n",
      "\n",
      "  [[-6.83646635e-01  9.21935071e-01  7.95657126e-01]\n",
      "   [-9.13072332e-01  3.08852821e-01  2.44860192e-01]\n",
      "   [-9.52156432e-01 -4.14413232e-01  1.43927238e-01]]]]\n",
      "y_max=4,x_max = 3, [[[[-0.25242947 -1.10845956  1.8432996 ]\n",
      "   [-1.373889   -0.03932287  0.14952495]\n",
      "   [ 1.57419656 -0.70422863 -0.02676983]]\n",
      "\n",
      "  [[-0.30690726  0.23722326  0.69192598]\n",
      "   [-1.56311    -0.22194953 -0.20530898]\n",
      "   [-0.12674518 -0.51152859  0.21678039]]\n",
      "\n",
      "  [[-0.05981441  0.82859678  0.53864593]\n",
      "   [-0.58217327  0.14573243  0.87660047]\n",
      "   [-0.11602285  1.39945545 -0.75195545]]]\n",
      "\n",
      "\n",
      " [[[ 1.77857612 -0.24868108  2.00759241]\n",
      "   [ 0.63099028  1.59858283 -1.13712626]\n",
      "   [ 0.50921434  0.68324859 -1.91458164]]\n",
      "\n",
      "  [[-1.09560144  0.59341059  1.47906806]\n",
      "   [ 0.67538955 -0.53174213 -0.5668139 ]\n",
      "   [-0.91304768  0.91174495  0.93619767]]\n",
      "\n",
      "  [[-1.81510213 -0.91307233  0.30885282]\n",
      "   [-0.26929717 -0.95215643 -0.41441323]\n",
      "   [ 0.45936002  0.26746225  0.48943666]]]]\n",
      "y_max=4,x_max = 4, [[[[-1.10845956e+00  1.84329960e+00 -1.65008438e+00]\n",
      "   [-3.93228742e-02  1.49524951e-01  5.54141876e-01]\n",
      "   [-7.04228633e-01 -2.67698344e-02 -5.52936092e-02]]\n",
      "\n",
      "  [[ 2.37223259e-01  6.91925977e-01 -1.63771426e+00]\n",
      "   [-2.21949531e-01 -2.05308977e-01  1.17524740e+00]\n",
      "   [-5.11528587e-01  2.16780390e-01 -2.19178336e-01]]\n",
      "\n",
      "  [[ 8.28596780e-01  5.38645926e-01  1.38645951e-01]\n",
      "   [ 1.45732433e-01  8.76600465e-01 -9.09821224e-01]\n",
      "   [ 1.39945545e+00 -7.51955452e-01 -1.72473698e-01]]]\n",
      "\n",
      "\n",
      " [[[-2.48681075e-01  2.00759241e+00  1.85364706e-03]\n",
      "   [ 1.59858283e+00 -1.13712626e+00 -2.40478590e+00]\n",
      "   [ 6.83248586e-01 -1.91458164e+00  9.57784405e-01]]\n",
      "\n",
      "  [[ 5.93410593e-01  1.47906806e+00 -1.52329378e-01]\n",
      "   [-5.31742131e-01 -5.66813896e-01  3.05534490e-01]\n",
      "   [ 9.11744955e-01  9.36197669e-01 -1.76387823e+00]]\n",
      "\n",
      "  [[-9.13072332e-01  3.08852821e-01  2.44860192e-01]\n",
      "   [-9.52156432e-01 -4.14413232e-01  1.43927238e-01]\n",
      "   [ 2.67462247e-01  4.89436657e-01 -4.58183657e-01]]]]\n",
      "[[ 6.58989223e-01 -2.60027883e-01 -2.52429466e-01 -1.10845956e+00\n",
      "   9.61757196e-01  6.54402912e-01 -3.06907256e-01  2.37223259e-01\n",
      "   1.30081129e+00  2.12125247e-01 -5.98144146e-02  8.28596780e-01]\n",
      " [-2.60027883e-01  1.23237399e+00 -1.10845956e+00  1.84329960e+00\n",
      "   6.54402912e-01  1.20023782e-01  2.37223259e-01  6.91925977e-01\n",
      "   2.12125247e-01 -1.36801144e+00  8.28596780e-01  5.38645926e-01]\n",
      " [ 1.23237399e+00  1.23346458e+00  1.84329960e+00 -1.65008438e+00\n",
      "   1.20023782e-01 -6.86277409e-01  6.91925977e-01 -1.63771426e+00\n",
      "  -1.36801144e+00  9.77561881e-01  5.38645926e-01  1.38645951e-01]\n",
      " [-2.52429466e-01 -1.10845956e+00 -1.37388900e+00 -3.93228742e-02\n",
      "  -3.06907256e-01  2.37223259e-01 -1.56311000e+00 -2.21949531e-01\n",
      "  -5.98144146e-02  8.28596780e-01 -5.82173268e-01  1.45732433e-01]\n",
      " [-1.10845956e+00  1.84329960e+00 -3.93228742e-02  1.49524951e-01\n",
      "   2.37223259e-01  6.91925977e-01 -2.21949531e-01 -2.05308977e-01\n",
      "   8.28596780e-01  5.38645926e-01  1.45732433e-01  8.76600465e-01]\n",
      " [ 1.84329960e+00 -1.65008438e+00  1.49524951e-01  5.54141876e-01\n",
      "   6.91925977e-01 -1.63771426e+00 -2.05308977e-01  1.17524740e+00\n",
      "   5.38645926e-01  1.38645951e-01  8.76600465e-01 -9.09821224e-01]\n",
      " [-1.37388900e+00 -3.93228742e-02  1.57419656e+00 -7.04228633e-01\n",
      "  -1.56311000e+00 -2.21949531e-01 -1.26745183e-01 -5.11528587e-01\n",
      "  -5.82173268e-01  1.45732433e-01 -1.16022845e-01  1.39945545e+00]\n",
      " [-3.93228742e-02  1.49524951e-01 -7.04228633e-01 -2.67698344e-02\n",
      "  -2.21949531e-01 -2.05308977e-01 -5.11528587e-01  2.16780390e-01\n",
      "   1.45732433e-01  8.76600465e-01  1.39945545e+00 -7.51955452e-01]\n",
      " [ 1.49524951e-01  5.54141876e-01 -2.67698344e-02 -5.52936092e-02\n",
      "  -2.05308977e-01  1.17524740e+00  2.16780390e-01 -2.19178336e-01\n",
      "   8.76600465e-01 -9.09821224e-01 -7.51955452e-01 -1.72473698e-01]\n",
      " [-4.71853569e-01 -1.05629618e+00  1.77857612e+00 -2.48681075e-01\n",
      "   8.76387200e-01  2.63921840e-01 -1.09560144e+00  5.93410593e-01\n",
      "  -1.87602600e+00 -6.83646635e-01 -1.81510213e+00 -9.13072332e-01]\n",
      " [-1.05629618e+00  3.17709774e-01 -2.48681075e-01  2.00759241e+00\n",
      "   2.63921840e-01  2.16770236e-01  5.93410593e-01  1.47906806e+00\n",
      "  -6.83646635e-01  9.21935071e-01 -9.13072332e-01  3.08852821e-01]\n",
      " [ 3.17709774e-01 -3.78260448e-01  2.00759241e+00  1.85364706e-03\n",
      "   2.16770236e-01  2.69205205e-02  1.47906806e+00 -1.52329378e-01\n",
      "   9.21935071e-01  7.95657126e-01  3.08852821e-01  2.44860192e-01]\n",
      " [ 1.77857612e+00 -2.48681075e-01  6.30990277e-01  1.59858283e+00\n",
      "  -1.09560144e+00  5.93410593e-01  6.75389555e-01 -5.31742131e-01\n",
      "  -1.81510213e+00 -9.13072332e-01 -2.69297175e-01 -9.52156432e-01]\n",
      " [-2.48681075e-01  2.00759241e+00  1.59858283e+00 -1.13712626e+00\n",
      "   5.93410593e-01  1.47906806e+00 -5.31742131e-01 -5.66813896e-01\n",
      "  -9.13072332e-01  3.08852821e-01 -9.52156432e-01 -4.14413232e-01]\n",
      " [ 2.00759241e+00  1.85364706e-03 -1.13712626e+00 -2.40478590e+00\n",
      "   1.47906806e+00 -1.52329378e-01 -5.66813896e-01  3.05534490e-01\n",
      "   3.08852821e-01  2.44860192e-01 -4.14413232e-01  1.43927238e-01]\n",
      " [ 6.30990277e-01  1.59858283e+00  5.09214342e-01  6.83248586e-01\n",
      "   6.75389555e-01 -5.31742131e-01 -9.13047685e-01  9.11744955e-01\n",
      "  -2.69297175e-01 -9.52156432e-01  4.59360016e-01  2.67462247e-01]\n",
      " [ 1.59858283e+00 -1.13712626e+00  6.83248586e-01 -1.91458164e+00\n",
      "  -5.31742131e-01 -5.66813896e-01  9.11744955e-01  9.36197669e-01\n",
      "  -9.52156432e-01 -4.14413232e-01  2.67462247e-01  4.89436657e-01]\n",
      " [-1.13712626e+00 -2.40478590e+00 -1.91458164e+00  9.57784405e-01\n",
      "  -5.66813896e-01  3.05534490e-01  9.36197669e-01 -1.76387823e+00\n",
      "  -4.14413232e-01  1.43927238e-01  4.89436657e-01 -4.58183657e-01]]\n"
     ]
    }
   ],
   "source": [
    "col = np.zeros((N,C, filter_h, filter_w, out_h, out_w)) # Num entries per convolution (N x C x filter_w x filter H) , num convolutions per Convolution (out_h x out_w). \n",
    "\n",
    "    # For loops...\n",
    "for y in range(filter_h):\n",
    "        # for each element of filter_h, we are extracting all the elements it has touched.\n",
    "        y_max = y + stride * out_h\n",
    "        #print(y_max)\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride * out_w\n",
    "            # For each element of the kernel, we are extracting all the entries that it has touched.\n",
    "            # Extracts the elements of size out_h x out_w for each filter_h x filter_w combo\n",
    "            print(f'{y_max=},{x_max = }, {image[:, :, y:y_max:stride, x:x_max:stride]}')\n",
    "            col[:, :, y, x, :, :] = image[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N * out_h * out_w, -1)\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_h = (4 + 2 * pad - 2) // stride + 1\n",
    "out_w = (W + 2 * pad - filter_w) // stride + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for y in range(filter_h):\n",
    "        y_max = y + stride * out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride * out_w\n",
    "            col[:, :, y, x, :, :] = image[:, :, y:y_max:stride, x:x_max:stride]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "W = 4\n",
    "stride = 2\n",
    "filter_w = 2\n",
    "pad = 0\n",
    "out_w = (W + 2 * pad - filter_w) // stride + 1\n",
    "print(out_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Im2Col, Col2Im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N,C,H,W = 2,3,4,4\n",
    "img = Tensor(np.random.randn(N,C,H,W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mIm2Col\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[30], line 29\u001b[0m, in \u001b[0;36mIm2Col\u001b[1;34m(input_image, kernel_h, kernel_w, stride, pad)\u001b[0m\n\u001b[0;32m     25\u001b[0m         x_max \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m stride\u001b[38;5;241m*\u001b[39mout_w\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;66;03m# We extract the num of entries each part of the kernel touches\u001b[39;00m\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;66;03m# Each extraction will be of shape [N x C x out_h x out_w] because out_h x out_W is the num of convs performed.\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m         \u001b[43mcol\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m padded_data[:,:,y:y_max:stride, x:x_max:stride]\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m col\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(N\u001b[38;5;241m*\u001b[39mout_h\u001b[38;5;241m*\u001b[39mout_w, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Tensor' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "output = Im2Col(img,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(data = [[[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]], grad = 0)\n"
     ]
    }
   ],
   "source": [
    "print(t.pad(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(data = [[[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]], grad = 0)\n"
     ]
    }
   ],
   "source": [
    "t = Tensor(np.zeros(((2,3,4))))\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensor import Tensor\n",
    "\n",
    "def Im2Col(input_image, kernel_h, kernel_w, stride=1, pad=0):\n",
    "    '''\n",
    "    input_image: Tensor of shape [BS x C x H x W]\n",
    "    '''\n",
    "    N,C,H,W = input_image.shape\n",
    "\n",
    "    assert (H + 2*pad - kernel_h) % stride == 0\n",
    "    assert (W + 2*pad - kernel_w) % stride == 0\n",
    "\n",
    "    out_h = (H + 2*pad - kernel_h)//stride + 1\n",
    "    out_w = (H + 2*pad - kernel_w)//stride + 1\n",
    "\n",
    "    # pad should be a tuple specifying how much you want to pad height and width\n",
    "    padded_data = input_image.pad(pad)\n",
    "\n",
    "    col = Tensor(np.zeros((N,C, kernel_h, kernel_w, out_h, out_w)))\n",
    "\n",
    "    for y in range(kernel_h):\n",
    "        y_max = y + stride*out_h # y_max is the max idx the kernel sees.\n",
    "\n",
    "        for x in range(kernel_w):\n",
    "            x_max = x + stride*out_w\n",
    "\n",
    "            # We extract the num of entries each part of the kernel touches\n",
    "            # Each extraction will be of shape [N x C x out_h x out_w] because out_h x out_W is the num of convs performed.\n",
    "            col[:,:,y,x] = padded_data[:,:,y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    return col.transpose(0,4,5,1,2,3).reshape(N*out_h*out_w, -1) \n",
    "    # We want [N*out_h*out_w, num entries ] -> the output images for each image in batch x filter size * C (num of entries)\n",
    "\n",
    "\n",
    "def Col2Im(col, img_shape, kernel_h, kernel_w, stride = 1, pad = 0):\n",
    "\n",
    "    N, C, H, W = img_shape\n",
    "\n",
    "    out_h = (H + 2 * pad - kernel_h) // stride + 1\n",
    "    out_w = (W + 2 * pad - kernel_w) // stride + 1\n",
    "\n",
    "    col= col.reshape(N,out_h, out_w, C, kernel_h, kernel_w).transpose(0,3,4,5,1,2)\n",
    "\n",
    "    image = np.zeros((N,C,H + 2 * pad + stride - 1, W + 2 * pad + stride - 1)) # ???\n",
    "    # we want to get the padded matrix, \n",
    "\n",
    "    for y in range(kernel_h):\n",
    "        y_max = y + stride * out_h\n",
    "        for x in range(kernel_w):\n",
    "            x_max = x + stride * out_w\n",
    "            image[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "    \n",
    "    print('image after', image.shape)\n",
    "    return image[:, :, pad:H + pad, pad:W + pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = lambda x: x+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "C = 3\n",
    "FH, FW = 2,2\n",
    "H,W = 4,4\n",
    "N = 2\n",
    "\n",
    "out_h = H - FH + 1\n",
    "out_w = W - FW + 1\n",
    "\n",
    "dout = np.random.randn(N, K, out_h, out_w)\n",
    "x_col = np.random.randn(N*out_h*out_w, C*FH*FW) # [num convs , patch]\n",
    "dout_t = dout.transpose(0,2,3,1).reshape(-1,K) # [num_convs, K]\n",
    "\n",
    "dw_col = x_col.T @ dout_t# [num_convs, patch].T x [num_convs x K] -> [patch x K]\n",
    "dw_col = dw_col.transpose(1,0).reshape(K, C, FH, FW) # dw -> K,C, FH, FW\n",
    "\n",
    "dout_t2 = dout.transpose(0,2,3,1).reshape(K,-1)\n",
    "dw = dout_t2 @ x_col # [K, num_convs] x [num_convs x patch]\n",
    "dw = dw.reshape(K, C, FH, FW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ -3.49113263,  -0.02521229],\n",
       "         [ -2.75414599,  -4.9803317 ]],\n",
       "\n",
       "        [[  5.05131694,   2.95751468],\n",
       "         [  2.85769525,  -5.43319955]],\n",
       "\n",
       "        [[ -4.60997143,   4.10372013],\n",
       "         [  3.50876173,  -6.79019394]]],\n",
       "\n",
       "\n",
       "       [[[  3.12234928,   2.40180591],\n",
       "         [  2.40275619,   1.33252241]],\n",
       "\n",
       "        [[  3.57804806,  -1.78218324],\n",
       "         [ -0.10269539,  -5.09705624]],\n",
       "\n",
       "        [[  0.60290801,  -1.61190165],\n",
       "         [ -2.86592964,  -4.43652769]]],\n",
       "\n",
       "\n",
       "       [[[ -1.07950074,   0.42269824],\n",
       "         [ -4.28748527,  -3.55926836]],\n",
       "\n",
       "        [[  2.44073626,  -4.14538545],\n",
       "         [ -1.93794666,  -0.07649018]],\n",
       "\n",
       "        [[  5.64914391,  -1.93692556],\n",
       "         [ -0.12822287,   2.28227619]]],\n",
       "\n",
       "\n",
       "       [[[ -0.63614634,   1.59308568],\n",
       "         [  3.057244  ,  -1.73683581]],\n",
       "\n",
       "        [[-12.95588836,   2.1228131 ],\n",
       "         [ -8.22367565,  13.05672009]],\n",
       "\n",
       "        [[ -6.48097848,   1.79922165],\n",
       "         [  0.1304148 ,   3.53623333]]],\n",
       "\n",
       "\n",
       "       [[[ -1.09407536,   4.54948411],\n",
       "         [  4.83510545,  -2.67055751]],\n",
       "\n",
       "        [[  2.3320129 ,   1.19680171],\n",
       "         [ -1.80113882,   1.26339337]],\n",
       "\n",
       "        [[  4.24649737,  -2.78839368],\n",
       "         [ -0.60045286,   3.73891816]]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensor import Tensor\n",
    "\n",
    "def Im2Col(input_image, kernel_h, kernel_w, stride=1, pad=0):\n",
    "    '''\n",
    "    input_image: Tensor of shape [BS x C x H x W]\n",
    "    '''\n",
    "    N,C,H,W = input_image.shape\n",
    "\n",
    "    assert (H + 2*pad - kernel_h) % stride == 0\n",
    "    assert (W + 2*pad - kernel_w) % stride == 0\n",
    "\n",
    "    out_h = (H + 2*pad - kernel_h)//stride + 1\n",
    "    out_w = (H + 2*pad - kernel_w)//stride + 1\n",
    "\n",
    "    # pad should be a tuple specifying how much you want to pad height and width\n",
    "    padded_data = input_image.pad(pad)\n",
    "\n",
    "    col = Tensor(np.zeros((N,C, kernel_h, kernel_w, out_h, out_w)))\n",
    "    print('wut')\n",
    "    print(col.shape)\n",
    "\n",
    "    for y in range(kernel_h):\n",
    "        y_max = y + stride*out_h # y_max is the max idx the kernel sees. \n",
    "        # Why? because stride is the amount we move the slide the kernel for each convolution & out_h is the num of convs we perform along y.\n",
    "\n",
    "        for x in range(kernel_w):\n",
    "            x_max = x + stride*out_w\n",
    "\n",
    "            # We extract the num of entries each part of the kernel touches.\n",
    "            # E.g a 2x2 kernel -> what entries of the image does k_1,1 see?\n",
    "            # Each extraction will be of shape [N x C x out_h x out_w] because out_h x out_W is the num of convs performed.\n",
    "            #print(col[:,:,y,x,:,:].shape)\n",
    "            #print(padded_data[:,:,y:y_max:stride, x:x_max:stride].shape)\n",
    "            col[:,:,y,x,:,:] = padded_data[:,:,y:y_max:stride, x:x_max:stride]\n",
    "    print(col.shape)\n",
    "    return col.transpose((0,4,5,1,2,3)).reshape((N*out_h*out_w, -1))  # convs x patches\n",
    "    # We want [N*out_h*out_w, num entries ] -> the output images for each image in batch x filter size * C (num of entries)\n",
    "\n",
    "\n",
    "def Col2Im(col, img_shape, kernel_h, kernel_w, stride = 1, pad = 0):\n",
    "\n",
    "    N, C, H, W = img_shape\n",
    "\n",
    "    out_h = (H + 2 * pad - kernel_h) // stride + 1\n",
    "    out_w = (W + 2 * pad - kernel_w) // stride + 1\n",
    "\n",
    "    col= col.reshape((N,out_h, out_w, C, kernel_h, kernel_w)).transpose((0,3,4,5,1,2))\n",
    "\n",
    "    image = Tensor(np.zeros((N,C,H + 2 * pad + stride - 1, W + 2 * pad + stride - 1))) # ???\n",
    "    print(f'{image.shape=}')\n",
    "    # we want to get the padded matrix, but why + stride?\n",
    "\n",
    "    # Essentially takes and disperses. \n",
    "    for y in range(kernel_h):\n",
    "        y_max = y + stride * out_h\n",
    "        for x in range(kernel_w):\n",
    "            x_max = x + stride * out_w\n",
    "            # += because of total derivative. \n",
    "            # y:y_max:stride are the indices (of the img) seen by the kernel idx (y,x) as it slides along.\n",
    "            # the indices tell us which indices (entries of X) w has seen. \n",
    "            # image[:, :, y:y_max:stride, x:x_max:stride] -> the specific x val, dL/dx_i,j\n",
    "            image[:, :, y:y_max:stride, x:x_max:stride] = col[:, :, y, x] + image[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    print('image after', image.shape)\n",
    "\n",
    "    return image[:, :, pad:H + pad, pad:W + pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tensor(np.zeros((3,4,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3 = col2im(col.data, (N,C,H,W), 2,2, padding = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(data = [[[[-0.60302473 -0.15342031  1.3303752  -1.02497474]\n",
      "   [ 0.01827547 -0.06711329  0.25193848 -0.75097839]\n",
      "   [ 1.32224517 -1.51295631  1.07776847  1.72961163]\n",
      "   [-0.58448618  1.82300701  0.12378387  1.18943251]]]], grad = 0)\n",
      "[[[[-6.03024730e-01 -1.17839505e+00  2.70213956e-01 -7.50978389e-01]\n",
      "   [-1.58006959e+00  2.76563064e+00  2.24408655e-03  2.40001364e+00]\n",
      "   [-8.18091676e-01  1.63975766e+00  3.11665741e+00  1.32970695e+00]\n",
      "   [ 1.32224517e+00  2.16655321e-01 -4.60702310e-01  1.18943251e+00]]]]\n"
     ]
    }
   ],
   "source": [
    "print(img)\n",
    "print(img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wut\n",
      "(1, 1, 2, 2, 3, 3)\n",
      "(1, 1, 3, 3)\n",
      "(1, 1, 3, 3)\n",
      "(1, 1, 3, 3)\n",
      "(1, 1, 3, 3)\n",
      "(1, 1, 3, 3)\n",
      "(1, 1, 3, 3)\n",
      "(1, 1, 3, 3)\n",
      "(1, 1, 3, 3)\n",
      "(1, 1, 2, 2, 3, 3)\n",
      "Tensor(data = [[[[-0.79608946  1.02926435 -2.0582537   0.26175885]\n",
      "   [ 1.684163   -0.93418648 -1.03344877 -1.20104663]\n",
      "   [ 0.73651828 -0.57770761 -1.78893679  0.49821182]\n",
      "   [ 0.32410088 -1.6996683   1.77529668 -2.41897758]]]], grad = 0)\n",
      "Tensor(data = [[-0.79608946  1.02926435  1.684163   -0.93418648]\n",
      " [ 1.02926435 -2.0582537  -0.93418648 -1.03344877]\n",
      " [-2.0582537   0.26175885 -1.03344877 -1.20104663]\n",
      " [ 1.684163   -0.93418648  0.73651828 -0.57770761]\n",
      " [-0.93418648 -1.03344877 -0.57770761 -1.78893679]\n",
      " [-1.03344877 -1.20104663 -1.78893679  0.49821182]\n",
      " [ 0.73651828 -0.57770761  0.32410088 -1.6996683 ]\n",
      " [-0.57770761 -1.78893679 -1.6996683   1.77529668]\n",
      " [-1.78893679  0.49821182  1.77529668 -2.41897758]], grad = 0)\n",
      "Tensor(data = [[[[-0.79608946  2.05852869 -4.11650741  0.26175885]\n",
      "   [ 3.36832599 -3.73674592 -4.13379508 -2.40209326]\n",
      "   [ 1.47303657 -2.31083045 -7.15574717  0.99642365]\n",
      "   [ 0.32410088 -3.3993366   3.55059337 -2.41897758]]]], grad = 0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "col = Im2Col(img, 2,2)\n",
    "print(img)\n",
    "print(col)\n",
    "\n",
    "img2 = Col2Im(col, (N,C,H,W), 2,2)\n",
    "print(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 4)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.03909948"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.01954974*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from module import Module\n",
    "from tensor import Tensor\n",
    "#from utils import Im2Col, Col2Im\n",
    "\n",
    "\n",
    "class Convolution2D(Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, pad=0):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.pad= pad\n",
    "\n",
    "        self.kernel_weights = Tensor(np.random.randn(out_channels,in_channels, *kernel_size))\n",
    "        self.kernel_bias = Tensor(np.zeros(out_channels)) # we add a bias for each channel\n",
    "\n",
    "    def forward(self, x):\n",
    "        self._cache['x'] = x\n",
    "        out_channels, in_channels, kernel_h, kernel_w = self.kernel_weights.shape\n",
    "        # W_out = (W_in - K + 2P)/S + 1 \n",
    "        N, C, H, W = x.shape\n",
    "        H_out = int((H - kernel_h + 2*self.pad)/ self.stride + 1)\n",
    "        W_out = int((W - kernel_w + 2*self.pad)/ self.stride + 1)\n",
    "        print(f'{H_out=}, {W_out=}')\n",
    "\n",
    "        col_weights = self.kernel_weights.reshape((out_channels , -1)).transpose() #[patch,K]\n",
    "        col = Im2Col(x, kernel_h, kernel_w, self.stride, self.pad) # [convs x patch]\n",
    "        print(f'{col_weights.shape=}, {col.shape=}')\n",
    "\n",
    "        output = col @ col_weights + self.kernel_bias # convs x K\n",
    "        output =  output.reshape((N, H_out, W_out, -1)).transpose((0, 3, 1, 2))\n",
    "\n",
    "        self._cache['x_col'] = col\n",
    "        self._cache['col_weights'] = col_weights\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self, dout):\n",
    "        # output shape -> N,K, Hout, Wout\n",
    "        dout = dout.transpose((0,2,3,1)).reshape((-1, self.out_channels)) # [N, Hout, Wout, K] -> [N*Hout*Wout, K] -> [convs, K]\n",
    "        db = dout.sum_(axis = 0) # we sum along the N*Hout*Wout axis -> (K,)\n",
    "        print(f\"{dout.shape=}, {self._cache['x_col'].shape=}\")\n",
    "        dw_col = self._cache['x_col'].transpose() @ dout # [patch x convs] x [convs x K]-> [patch x K], dout is the filter!\n",
    "        print(f'{dw_col.shape=}')\n",
    "        dw = dw_col.transpose((1,0)).reshape((self.out_channels, self.in_channels, *self.kernel_size))\n",
    "\n",
    "        # Downstream gradient, dx = a full convolution of 180 deg rotated filter with dout.\n",
    "        print(f\"{dout.shape=}, {self._cache['col_weights'].shape=}, {self._cache['col_weights'].transpose().shape=}\")\n",
    "        dx_col = dout @ self._cache['col_weights'].transpose() # [convs, K] x [K, patch] -> [convs x patch]\n",
    "        dx = Col2Im(dx_col, self._cache['x'].shape, *self.kernel_size, self.stride, self.pad)\n",
    "\n",
    "        self._cache['weights'] = dw\n",
    "        self._cache['bias'] = db\n",
    "\n",
    "        return dx\n",
    "\n",
    "    def __call__(self,x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class MyBatchNorm2d(nn.BatchNorm2d):\n",
    "    def __init__(self, num_features, eps=1e-5, momentum=0.1,\n",
    "                 affine=True, track_running_stats=True):\n",
    "        super(MyBatchNorm2d, self).__init__(\n",
    "            num_features, eps, momentum, affine, track_running_stats)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self._check_input_dim(input)\n",
    "\n",
    "        exponential_average_factor = 0.0\n",
    "\n",
    "        if self.training and self.track_running_stats:\n",
    "            if self.num_batches_tracked is not None:\n",
    "                self.num_batches_tracked += 1\n",
    "                if self.momentum is None:  # use cumulative moving average\n",
    "                    exponential_average_factor = 1.0 / float(self.num_batches_tracked)\n",
    "                else:  # use exponential moving average\n",
    "                    exponential_average_factor = self.momentum\n",
    "\n",
    "        # calculate running estimates\n",
    "        if self.training:\n",
    "            mean = input.mean([0, 2, 3])\n",
    "            print(mean)\n",
    "            # use biased var in train\n",
    "            var = input.var([0, 2, 3], unbiased=False)\n",
    "            n = input.numel() / input.size(1)\n",
    "            print(exponential_average_factor)\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = exponential_average_factor * mean+ (1 - exponential_average_factor) * self.running_mean\n",
    "                # update running_var with unbiased var\n",
    "                self.running_var = exponential_average_factor * var * n / (n - 1)+ (1 - exponential_average_factor) * self.running_var\n",
    "        else:\n",
    "            mean = self.running_mean\n",
    "            var = self.running_var\n",
    "\n",
    "        print(var)\n",
    "        print(torch.sqrt(var[None, :, None, None] + self.eps))\n",
    "        input = (input - mean[None, :, None, None]) / (torch.sqrt(var[None, :, None, None] + self.eps))\n",
    "        print(input)\n",
    "        if self.affine:\n",
    "            input = input * self.weight[None, :, None, None] + self.bias[None, :, None, None]\n",
    "\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0333,  0.2346,  0.1881])\n",
      "0.1\n",
      "tensor([1.1515, 1.0253, 0.8117])\n",
      "tensor([[[[1.0731]],\n",
      "\n",
      "         [[1.0126]],\n",
      "\n",
      "         [[0.9009]]]])\n",
      "tensor([[[[-0.9140,  1.5541, -0.4857,  2.6703],\n",
      "          [-2.2852,  1.3853, -0.3243, -0.2378],\n",
      "          [-0.2192, -0.7823,  0.6649,  1.4055],\n",
      "          [-0.9424,  0.1205,  1.0601,  0.1943]],\n",
      "\n",
      "         [[-2.1895,  1.3304,  0.2900,  1.7394],\n",
      "          [-1.4406,  1.4581,  0.2652,  1.5393],\n",
      "          [ 0.8078,  0.7346,  0.0826, -0.7826],\n",
      "          [ 0.5718, -0.0468, -0.2557, -0.6868]],\n",
      "\n",
      "         [[-1.3961,  0.9195,  0.5097,  0.0304],\n",
      "          [ 0.4641,  0.3996, -0.2782, -0.4890],\n",
      "          [ 0.3179, -2.0279, -0.0979,  1.3985],\n",
      "          [-0.9711, -0.2634,  0.6741, -0.4993]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5729,  0.2872,  1.1061,  0.2904],\n",
      "          [ 1.0168, -0.1672, -0.8937,  0.3250],\n",
      "          [-1.0344, -0.4336, -0.7510, -1.4438],\n",
      "          [-0.8650,  0.1839, -0.5817, -0.4762]],\n",
      "\n",
      "         [[-0.2066,  1.9514, -1.1443, -0.3223],\n",
      "          [ 0.0250,  0.4032, -0.3078, -0.9256],\n",
      "          [ 1.2806, -1.2648,  0.1721, -0.7353],\n",
      "          [ 0.3961, -0.5908, -1.0195, -1.1288]],\n",
      "\n",
      "         [[ 1.5201,  0.4737,  0.7080, -0.1334],\n",
      "          [-2.8910, -1.3926,  1.4024,  0.0575],\n",
      "          [ 0.8429,  0.8665,  0.4317,  1.3654],\n",
      "          [-0.1066, -0.8162, -0.9142, -0.1051]]]])\n"
     ]
    }
   ],
   "source": [
    "bn2 = MyBatchNorm2d(3)\n",
    "o2 = bn2(torch_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "img_data = img.data\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0333)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_img[:,0,:,:].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.033336872700601816\n"
     ]
    }
   ],
   "source": [
    "mean=0\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        for k in range(4):\n",
    "            mean+=torch_img[i,0,j,k].item()\n",
    "\n",
    "mean /= 32\n",
    "\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0333,  0.2346,  0.1881])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch_img, axis=[0,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1., 1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H_out=2, W_out=2\n",
      "wut\n",
      "(1, 1, 2, 2, 2, 2)\n",
      "(1, 1, 2, 2, 2, 2)\n",
      "col_weights.shape=(4, 1), col.shape=(4, 4)\n",
      "dout.shape=(4, 1), self._cache['x_col'].shape=(4, 4)\n",
      "dw_col.shape=(4, 1)\n",
      "dout.shape=(4, 1), self._cache['col_weights'].shape=(4, 1), self._cache['col_weights'].transpose().shape=(1, 4)\n",
      "image.shape=(1, 1, 5, 5)\n",
      "image after (1, 1, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "conv_layer = Convolution2D(in_channels=1, out_channels=1, stride=2, kernel_size = (2,2))\n",
    "cov_output = conv_layer(img)\n",
    "dout = Tensor(np.ones_like(cov_output.data))\n",
    "dx=conv_layer.backward(dout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 4, 4)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module import Module\n",
    "\n",
    "class BatchNorm(Module):\n",
    "    def __init__(self, num_feats):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-10\n",
    "        self.gamma = Tensor(np.ones(num_feats))\n",
    "        self.beta = Tensor(np.zeros(num_feats))\n",
    "\n",
    "    def forward(self,x):\n",
    "        print('Changed', self.gamma, self.beta)\n",
    "        BS, C, H, W = x.shape\n",
    "        self._cache['x'] = x\n",
    "        mu = x.mean(axis = (0,2,3),keepdims=True) # find mean across batch\n",
    "        print(f'{mu=}')\n",
    "        var = Tensor(np.var(x.data, axis=(0,2,3), keepdims=True))\n",
    "        print(f'{var=}')\n",
    "        x_hat = (x-mu)/(var + self.eps)**0.5\n",
    "\n",
    "        self._cache['mu'] = mu\n",
    "        self._cache['var'] = var\n",
    "        self._cache['x_hat'] = x_hat\n",
    "\n",
    "        return self.gamma[None,:,None,None] * x_hat + self.beta[None,:,None,None]\n",
    "\n",
    "    def backward(self, dout):\n",
    "        x = self._cache['x']\n",
    "        BS = x.shape[0]\n",
    "        x_hat = self._cache['x_hat']\n",
    "        mu = self._cache['mu']\n",
    "        var = self._cache['var']\n",
    "\n",
    "        dBeta = dout.sum(axis=0)\n",
    "        dGamma = (dout * x).sum(axis = 0) # gets rid of row dim.\n",
    "        \n",
    "        dx_hat = Tensor(np.ones_like(x_hat)*self.gamma)\n",
    "\n",
    "        # dvar has shape [1 x F], a row vector. We broadcast it to add rows.\n",
    "        #we also need to broadcast gamma.\n",
    "        # but then we also need to sum over batch dim.\n",
    "        dVar = -0.5*self.gamma*(x - mu)*(var+ self.eps)**-1.5\n",
    "        dMu =  (dx_hat*-1*(var + self.eps)**-0.5).sum(axis=0) + dVar * (-2*(x - mu).sum(0))/ (BS+1) # 2nd part -> same batch get same mu, so we sum over it.\n",
    "        \n",
    "        # Downstream gradient\n",
    "        dx = dx_hat*(var-self.eps)**-0.5 +  dVar*2*(x - mu)*1/(BS+1) + dMu * Tensor(np.ones_like(x)*1/BS)\n",
    "        # nicer -> we don't have to worry abouit broadcasting since its wrt to x_hat (which is not broadcatsed along batch dim as mu/var is)\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# With square kernels and equal stride\n",
    "m = nn.Conv2d(16, 33, 3, stride=2)\n",
    "input = torch.randn(20, 16, 50, 100)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1399, -0.2331, -1.0112, -1.7236, -0.9243],\n",
      "        [ 1.2114, -1.0815,  0.5321,  0.0063,  0.3058]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "l = nn.Linear(10,5)\n",
    "ins = torch.randn(2,10)\n",
    "o = l(ins)\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor import Tensor\n",
    "import numpy as np\n",
    "BS, C = 5,6 # C= classes\n",
    "logits = Tensor(np.random.randn(BS,C))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from losses import CrossEntropyLossWithLogits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(data = [1 2 3 1 3], grad = 0)\n"
     ]
    }
   ],
   "source": [
    "targets = Tensor(np.random.randint(1,7, size=5))\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.data.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module import Module\n",
    "class CrossEntropyLossWithLogits(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "         # logits: shape -> [BS x C]\n",
    "         # targets: shape of [BS x 1] containing the index of the correct class.\n",
    "        \n",
    "        BS = logits.shape[0]\n",
    "        print(BS)\n",
    "        probs = logits.exp()/logits.exp().sum(axis=1, keepdims=True)\n",
    "        print(probs)\n",
    "\n",
    "        log_probs = probs.log()\n",
    "        out= log_probs[np.arange(BS),targets.data].mean(None, False)\n",
    "        self._cache['probs'] = probs\n",
    "        self._cache['targets'] = targets\n",
    "        return Tensor(-out.data, children=(logits,), backward_ = self.backward)\n",
    "    \n",
    "    def backward(self):\n",
    "        targets = self._cache['targets']\n",
    "        probs = self._cache['probs'].data.copy()\n",
    "        BS = probs.shape[0]\n",
    "        probs[np.arange(BS),targets.data] -= 1\n",
    "\n",
    "        logits.grad = probs * 1/BS\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(data = [3 4 2 5 1], grad = 0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(data = [[0.01618824 0.0181527  0.01873393 0.1679585  0.74541591 0.03355071]\n",
       " [0.11775372 0.38053407 0.06203892 0.05964667 0.1671127  0.21291392]\n",
       " [0.12206319 0.19953055 0.02061003 0.15993249 0.10279152 0.39507222]\n",
       " [0.07391515 0.09794317 0.10051482 0.15569171 0.55682644 0.01510871]\n",
       " [0.18563457 0.21681835 0.20503632 0.18754805 0.17118234 0.03378037]], grad = 0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce._cache['probs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(data = [[ 0.98962585 -1.21086516  0.9201605  -0.6060701   0.53535812 -0.8642163 ]\n",
       " [-1.41222666 -1.70222414 -0.72416473 -0.06802758 -0.61769996 -0.4327944 ]\n",
       " [ 0.62321913  1.3630514   0.05176756 -0.58478947 -0.12717756  1.01762086]\n",
       " [-1.11147511  0.92940638  0.19036226  0.92176364 -1.52820926  1.01642512]\n",
       " [-0.25773608  1.23570485  0.25171192  1.12128547  0.06688595 -0.36256591]], grad = 0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_true.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(data = [[-0.83146265 -0.71692878 -0.68541147  1.50796891  2.99819433 -0.10268995]\n",
       " [-0.66576502  0.50721538 -1.30659834 -1.34592209 -0.31569194 -0.07347239]\n",
       " [ 0.51279461  1.00422308 -1.26596655  0.7830075   0.34095856  1.68732432]\n",
       " [ 0.45066923  0.73213894  0.75805665  1.19562934  2.47000506 -1.13697702]\n",
       " [-0.39698921 -0.24170935 -0.29758213 -0.38673419 -0.47803996 -2.10088937]], grad = [[ 0.00323765 -0.19636946  0.00374679  0.0335917   0.14908318  0.00671014]\n",
       " [ 0.02355074  0.07610681 -0.18759222  0.01192933  0.03342254  0.04258278]\n",
       " [ 0.02441264  0.03990611  0.00412201 -0.1680135   0.0205583   0.07901444]\n",
       " [ 0.01478303 -0.18041137  0.02010296  0.03113834  0.11136529  0.00302174]\n",
       " [ 0.03712691  0.04336367  0.04100726 -0.16249039  0.03423647  0.00675607]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0032, -0.1964,  0.0037,  0.0336,  0.1491,  0.0067],\n",
       "        [ 0.0236,  0.0761, -0.1876,  0.0119,  0.0334,  0.0426],\n",
       "        [ 0.0244,  0.0399,  0.0041, -0.1680,  0.0206,  0.0790],\n",
       "        [ 0.0148, -0.1804,  0.0201,  0.0311,  0.1114,  0.0030],\n",
       "        [ 0.0371,  0.0434,  0.0410, -0.1625,  0.0342,  0.0068]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(data = 2.5238041700119673, grad = [1]) tensor(2.5238, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "logs = torch.tensor(logits.data, requires_grad=True)\n",
    "loss_true = F.cross_entropy(logs, torch.tensor(targets.data, dtype=torch.long))\n",
    "print(loss,loss_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(t):\n",
    "    out = Tensor(np.maximum(0,t.data), (t,))\n",
    "\n",
    "    def backward_():\n",
    "      t.grad += np.where(out.data > 0, out.grad, 0)\n",
    "\n",
    "    out.backward_ = backward_\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.grad = np.random.randn(o.shape[0],o.shape[1])\n",
    "o.backward_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(data = [[0.         0.         0.         1.50796891 2.99819433 0.        ]\n",
      " [0.         0.50721538 0.         0.         0.         0.        ]\n",
      " [0.51279461 1.00422308 0.         0.7830075  0.34095856 1.68732432]\n",
      " [0.45066923 0.73213894 0.75805665 1.19562934 2.47000506 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.        ]], grad = [[ 0.72236296 -0.63599729  1.04386782  0.48152774  0.57671519  0.49256578]\n",
      " [ 1.43123425  1.27770231  1.70889293 -0.52610961  0.05534279  1.17961273]\n",
      " [-1.32086715 -0.20955157  0.37325724 -1.51351102 -0.26797279  0.98404636]\n",
      " [-1.5531078   0.20738756  1.2686006   0.39666374  0.02674206 -1.03707938]\n",
      " [ 0.46347617 -0.7835005  -0.00950433  1.42494579  0.8167799  -0.33734168]])\n",
      "#####\n",
      "[[ 0.72236296 -0.63599729  1.04386782  0.48152774  0.57671519  0.49256578]\n",
      " [ 1.43123425  1.27770231  1.70889293 -0.52610961  0.05534279  1.17961273]\n",
      " [-1.32086715 -0.20955157  0.37325724 -1.51351102 -0.26797279  0.98404636]\n",
      " [-1.5531078   0.20738756  1.2686006   0.39666374  0.02674206 -1.03707938]\n",
      " [ 0.46347617 -0.7835005  -0.00950433  1.42494579  0.8167799  -0.33734168]]\n"
     ]
    }
   ],
   "source": [
    "print(o)\n",
    "print('#####')\n",
    "print(o.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00323765, -0.19636946,  0.00374679,  0.51511944,  0.72579837,\n",
       "         0.00671014],\n",
       "       [ 0.02355074,  1.35380912, -0.18759222,  0.01192933,  0.03342254,\n",
       "         0.04258278],\n",
       "       [-1.29645452, -0.16964546,  0.00412201, -1.68152452, -0.24741448,\n",
       "         1.0630608 ],\n",
       "       [-1.53832477,  0.0269762 ,  1.28870357,  0.42780208,  0.13810735,\n",
       "         0.00302174],\n",
       "       [ 0.03712691,  0.04336367,  0.04100726, -0.16249039,  0.03423647,\n",
       "         0.00675607]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "o=relu(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Tensor(data = [[0.01618824 0.0181527  0.01873393 0.1679585  0.74541591 0.03355071]\n",
      " [0.11775372 0.38053407 0.06203892 0.05964667 0.1671127  0.21291392]\n",
      " [0.12206319 0.19953055 0.02061003 0.15993249 0.10279152 0.39507222]\n",
      " [0.07391515 0.09794317 0.10051482 0.15569171 0.55682644 0.01510871]\n",
      " [0.18563457 0.21681835 0.20503632 0.18754805 0.17118234 0.03378037]], grad = 0)\n"
     ]
    }
   ],
   "source": [
    "ce = CrossEntropyLossWithLogits()\n",
    "\n",
    "loss = ce(logits, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_tensor = torch.tensor(targets.data, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=torch.tensor(logits.data).softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(data = [[-0.83146265 -0.71692878 -0.68541147  1.50796891  2.99819433 -0.10268995]\n",
       " [-0.66576502  0.50721538 -1.30659834 -1.34592209 -0.31569194 -0.07347239]\n",
       " [ 0.51279461  1.00422308 -1.26596655  0.7830075   0.34095856  1.68732432]\n",
       " [ 0.45066923  0.73213894  0.75805665  1.19562934  2.47000506 -1.13697702]\n",
       " [-0.39698921 -0.24170935 -0.29758213 -0.38673419 -0.47803996 -2.10088937]], grad = [[ 0.00323765 -0.19636946  0.00374679  0.0335917   0.14908318  0.00671014]\n",
       " [ 0.02355074  0.07610681 -0.18759222  0.01192933  0.03342254  0.04258278]\n",
       " [ 0.02441264  0.03990611  0.00412201 -0.1680135   0.0205583   0.07901444]\n",
       " [ 0.01478303 -0.18041137  0.02010296  0.03113834  0.11136529  0.00302174]\n",
       " [ 0.03712691  0.04336367  0.04100726 -0.16249039  0.03423647  0.00675607]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.backward()\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 1, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0162, 0.0182, 0.0187, 0.1680, 0.7454, 0.0336],\n",
       "        [0.1178, 0.3805, 0.0620, 0.0596, 0.1671, 0.2129],\n",
       "        [0.1221, 0.1995, 0.0206, 0.1599, 0.1028, 0.3951],\n",
       "        [0.0739, 0.0979, 0.1005, 0.1557, 0.5568, 0.0151],\n",
       "        [0.1856, 0.2168, 0.2050, 0.1875, 0.1712, 0.0338]], dtype=torch.float64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p #[torch.arange(BS),targets_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(data = 2.213570171811923, grad = 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 6.5131e-01, -4.6349e-01,  1.4009e+00,  ..., -4.5093e-01,\n",
       "           -8.8887e-01, -7.5581e-01],\n",
       "          [ 1.4307e-01, -2.7941e-01, -7.2097e-01,  ...,  8.4199e-01,\n",
       "           -3.1837e-01,  4.5393e-02],\n",
       "          [-3.8615e-01, -5.9359e-01, -6.2305e-02,  ..., -1.3753e+00,\n",
       "            4.9063e-01, -1.7188e-01],\n",
       "          ...,\n",
       "          [ 8.5481e-01,  1.7378e-01,  8.4781e-01,  ..., -5.6031e-01,\n",
       "            8.9470e-01,  5.7031e-01],\n",
       "          [-2.3531e-01, -1.3991e-01,  4.5517e-01,  ...,  7.5654e-03,\n",
       "            3.9916e-01,  1.6169e-02],\n",
       "          [ 7.9266e-01, -2.3006e-01, -1.6159e+00,  ..., -7.0827e-02,\n",
       "           -1.9055e-01,  6.7308e-01]],\n",
       "\n",
       "         [[-4.8235e-01,  3.1409e-01, -3.3970e-01,  ...,  8.2075e-01,\n",
       "           -1.1019e+00, -2.0103e-01],\n",
       "          [-1.3823e-01,  3.7822e-01, -1.0408e+00,  ...,  5.5848e-01,\n",
       "           -1.4116e-01, -6.4103e-01],\n",
       "          [ 1.0599e-01,  1.9530e-01, -2.8484e-01,  ...,  6.1921e-01,\n",
       "           -5.7693e-02,  1.1141e+00],\n",
       "          ...,\n",
       "          [ 8.7247e-01,  9.4435e-02,  4.5315e-01,  ...,  5.7706e-01,\n",
       "           -1.4465e-01, -5.4756e-01],\n",
       "          [-6.3616e-01, -6.5806e-01, -1.0474e+00,  ..., -1.0718e-01,\n",
       "           -5.6070e-01,  1.7891e-01],\n",
       "          [ 6.8621e-01, -1.7200e-01, -5.8543e-02,  ...,  5.4736e-01,\n",
       "            6.3467e-01,  4.6094e-02]],\n",
       "\n",
       "         [[-2.3771e-01,  6.5452e-02, -1.7418e-01,  ..., -9.1689e-01,\n",
       "            2.8695e-01,  4.3397e-01],\n",
       "          [ 3.6483e-01, -8.9054e-01,  7.2739e-01,  ..., -9.4194e-01,\n",
       "            7.6427e-01,  4.2796e-01],\n",
       "          [-4.3519e-01,  3.2262e-01,  1.3078e+00,  ...,  6.9213e-01,\n",
       "           -3.0743e-01, -3.3038e-01],\n",
       "          ...,\n",
       "          [-5.8428e-01,  5.3048e-02, -1.2522e+00,  ...,  6.7369e-01,\n",
       "            1.2525e+00,  2.3596e-01],\n",
       "          [-7.3399e-01, -7.4020e-01,  4.7051e-01,  ..., -1.8977e-01,\n",
       "           -2.0002e-01, -3.3870e-01],\n",
       "          [-1.3002e+00, -1.9844e-01,  5.8073e-02,  ..., -7.7617e-01,\n",
       "           -1.3410e-01,  5.0585e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-5.1325e-03,  2.6750e-01, -9.9728e-01,  ...,  2.6138e-02,\n",
       "            3.0881e-01, -4.0534e-01],\n",
       "          [ 3.8408e-01,  2.0386e-01, -1.0132e-01,  ...,  3.4712e-01,\n",
       "            7.1143e-01, -4.8206e-01],\n",
       "          [ 4.2390e-01,  3.7708e-01,  5.4904e-01,  ...,  2.1529e+00,\n",
       "           -1.3895e-01, -6.4555e-01],\n",
       "          ...,\n",
       "          [-5.1877e-02, -4.6769e-01, -4.3263e-01,  ..., -1.1361e+00,\n",
       "           -9.0997e-02, -4.2123e-01],\n",
       "          [ 3.1123e-01,  8.1911e-01,  2.9122e-01,  ...,  4.0939e-01,\n",
       "            1.7525e-01, -6.5757e-01],\n",
       "          [ 2.2027e-02, -2.7589e-01,  2.4323e-01,  ..., -4.0212e-01,\n",
       "            9.6362e-02, -4.9729e-02]],\n",
       "\n",
       "         [[-5.4295e-02,  4.1650e-01,  1.0405e-01,  ..., -7.1076e-01,\n",
       "            3.1356e-01,  7.4485e-01],\n",
       "          [-2.6865e-01,  1.2911e+00,  6.6538e-01,  ..., -1.2897e-01,\n",
       "           -7.7408e-01,  9.0665e-01],\n",
       "          [ 1.3024e-01, -5.5342e-02,  1.7600e-01,  ..., -9.2123e-01,\n",
       "           -7.3988e-01,  5.5357e-01],\n",
       "          ...,\n",
       "          [ 2.2231e-01, -1.8647e-01, -5.1402e-01,  ..., -2.1662e-01,\n",
       "           -2.3241e-01, -5.6421e-01],\n",
       "          [ 9.0595e-03,  6.7572e-01,  1.7365e-01,  ..., -8.2425e-01,\n",
       "           -3.0478e-01, -8.4952e-01],\n",
       "          [-7.6017e-01,  8.0734e-01,  1.9991e-01,  ..., -2.2450e-01,\n",
       "            6.5678e-01, -1.2046e-01]],\n",
       "\n",
       "         [[-9.8052e-01,  1.2878e+00, -1.3309e-01,  ..., -5.8870e-01,\n",
       "           -8.5905e-05,  2.3111e-01],\n",
       "          [-1.7840e-01,  1.6965e+00,  6.0438e-01,  ..., -5.8079e-02,\n",
       "            1.0898e+00, -2.3379e-01],\n",
       "          [ 6.1519e-02,  3.4528e-01,  2.2117e-01,  ...,  1.1882e+00,\n",
       "           -2.5169e-01, -1.1473e-01],\n",
       "          ...,\n",
       "          [ 1.9412e-01,  1.3344e-01,  1.4426e-01,  ...,  1.6057e-01,\n",
       "           -2.0596e-01, -1.9184e-01],\n",
       "          [ 1.0574e-01, -4.2726e-01, -1.2141e+00,  ..., -6.9422e-01,\n",
       "            3.7412e-01,  5.7505e-01],\n",
       "          [ 8.2041e-01,  5.1041e-01, -1.6257e-02,  ..., -3.1937e-01,\n",
       "           -1.6020e-01, -3.7508e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.4414e+00, -8.9763e-02, -3.4321e-01,  ..., -1.9814e-01,\n",
       "            7.2870e-01, -3.6035e-01],\n",
       "          [ 5.4030e-01, -2.0658e-01, -2.1936e-01,  ..., -8.1522e-02,\n",
       "            2.6590e-02,  5.1675e-01],\n",
       "          [ 5.5434e-01,  1.0224e+00, -8.2785e-01,  ...,  8.8198e-01,\n",
       "            5.5608e-02, -9.7407e-01],\n",
       "          ...,\n",
       "          [-5.9359e-01, -3.3633e-01,  3.4774e-01,  ...,  2.4444e-01,\n",
       "           -8.2590e-01,  1.8140e-01],\n",
       "          [-1.0381e+00, -5.8524e-01,  6.2174e-01,  ...,  9.6147e-01,\n",
       "           -5.4223e-01,  4.9546e-01],\n",
       "          [-1.0142e+00,  4.7593e-01,  2.3033e-01,  ..., -7.2887e-01,\n",
       "           -1.1191e-02,  1.2468e+00]],\n",
       "\n",
       "         [[ 5.2250e-01,  2.5364e-01,  4.0168e-01,  ..., -5.4728e-01,\n",
       "           -3.4256e-01, -7.3472e-02],\n",
       "          [ 3.5202e-01,  5.0761e-01,  1.0601e+00,  ...,  1.3144e+00,\n",
       "            1.0493e+00,  6.3539e-01],\n",
       "          [ 7.4603e-01,  8.1177e-02,  1.0972e+00,  ...,  1.3361e+00,\n",
       "           -7.5768e-01,  2.2904e-01],\n",
       "          ...,\n",
       "          [-1.3301e-01,  5.8410e-02,  3.4520e-01,  ..., -9.5722e-01,\n",
       "            9.4914e-01, -3.1728e-01],\n",
       "          [-2.8812e-01, -5.4836e-01, -5.1210e-01,  ..., -4.4260e-01,\n",
       "           -6.0032e-01,  2.4182e-01],\n",
       "          [-2.0496e-01,  3.9768e-01, -2.1856e-01,  ...,  8.9901e-01,\n",
       "            7.3995e-01, -3.6218e-01]],\n",
       "\n",
       "         [[-5.0058e-01, -5.5649e-02,  3.4010e-01,  ...,  1.4687e-01,\n",
       "            7.5379e-02,  2.0232e-01],\n",
       "          [-1.7351e-01,  3.8621e-01, -9.7170e-02,  ..., -5.2098e-01,\n",
       "            4.5286e-01,  1.9649e-01],\n",
       "          [-3.6247e-01, -2.5445e-01,  1.3407e+00,  ...,  7.2406e-03,\n",
       "           -6.8696e-01, -6.1369e-02],\n",
       "          ...,\n",
       "          [ 6.1234e-01, -3.6330e-01, -3.1395e-01,  ..., -7.1598e-01,\n",
       "           -1.3797e+00, -4.5829e-01],\n",
       "          [-4.5329e-01,  2.3143e-01,  4.5228e-01,  ..., -9.7157e-01,\n",
       "           -4.9776e-01, -3.3778e-01],\n",
       "          [-6.0588e-01,  6.0885e-01, -4.7631e-01,  ..., -2.0637e-01,\n",
       "            1.8633e-01, -8.0089e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.0040e+00,  4.0462e-01,  1.9655e+00,  ...,  1.4548e+00,\n",
       "           -9.1047e-02,  6.9918e-01],\n",
       "          [ 1.2497e+00, -3.5201e-01, -6.4673e-01,  ..., -7.6794e-01,\n",
       "           -8.4819e-01, -6.8407e-01],\n",
       "          [ 3.4214e-01, -6.5845e-01, -5.8109e-01,  ...,  3.9282e-01,\n",
       "           -6.9747e-01,  5.8142e-01],\n",
       "          ...,\n",
       "          [ 3.2835e-03,  1.0803e-01, -1.7732e-01,  ..., -6.4311e-01,\n",
       "            8.5379e-01, -5.1161e-01],\n",
       "          [ 6.4762e-01,  1.1187e+00, -7.9679e-01,  ..., -9.7476e-01,\n",
       "            2.3884e-01, -4.6980e-01],\n",
       "          [ 3.6098e-01, -1.9294e-01, -1.3674e-02,  ...,  9.3952e-01,\n",
       "           -5.5553e-01, -5.1464e-01]],\n",
       "\n",
       "         [[-6.0616e-01, -3.9453e-01, -9.1109e-01,  ...,  1.4514e-01,\n",
       "            2.4985e-01, -2.1613e-01],\n",
       "          [-1.7147e-01, -4.2811e-01, -5.9111e-01,  ..., -1.7908e-01,\n",
       "           -9.1158e-01,  9.9827e-02],\n",
       "          [-2.1237e-01,  1.3316e-02, -4.6224e-01,  ..., -8.1878e-01,\n",
       "            9.9827e-01, -2.8555e-01],\n",
       "          ...,\n",
       "          [-8.9787e-01,  7.3498e-01,  7.7709e-01,  ..., -9.9411e-02,\n",
       "           -1.9775e-01,  8.7459e-02],\n",
       "          [ 4.1752e-01, -5.1895e-01,  1.4440e-01,  ...,  1.3538e-01,\n",
       "            1.2057e-01, -1.0138e+00],\n",
       "          [ 1.9307e-01,  1.1886e-01,  6.1484e-01,  ..., -1.1387e+00,\n",
       "           -1.2842e+00,  1.3895e-01]],\n",
       "\n",
       "         [[-8.1884e-01, -7.5136e-01, -7.2927e-01,  ..., -1.4878e-02,\n",
       "           -1.1497e+00, -2.2581e-01],\n",
       "          [ 2.8888e-01, -5.0868e-01,  1.8355e-01,  ...,  1.4528e+00,\n",
       "           -7.6971e-01, -7.2442e-01],\n",
       "          [-6.1085e-02, -1.2641e+00,  6.1423e-01,  ...,  2.2181e-01,\n",
       "            6.8478e-01,  4.6558e-01],\n",
       "          ...,\n",
       "          [-3.7368e-01,  1.2095e-01, -4.2977e-01,  ..., -1.4655e+00,\n",
       "            4.5352e-01, -5.9436e-01],\n",
       "          [-2.8105e-01,  6.0210e-01,  1.4671e-01,  ..., -5.3006e-01,\n",
       "            1.7658e-01, -3.7412e-01],\n",
       "          [ 9.4839e-01,  3.0632e-01,  5.4772e-01,  ...,  1.1883e-01,\n",
       "           -2.8418e-01, -1.5861e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.2742e-01,  1.1421e+00, -4.3115e-01,  ..., -4.1539e-01,\n",
       "           -7.9139e-01,  2.7749e-01],\n",
       "          [ 8.3035e-01, -4.4951e-01, -2.7108e-01,  ..., -5.2763e-01,\n",
       "            3.1906e-01,  7.4475e-01],\n",
       "          [-2.0615e-01, -5.2339e-01, -2.2817e-01,  ..., -6.0373e-01,\n",
       "            2.9690e-02, -1.1051e-01],\n",
       "          ...,\n",
       "          [-4.1933e-01, -7.6438e-01,  9.6771e-01,  ..., -5.4917e-01,\n",
       "            9.7380e-02,  1.1848e-01],\n",
       "          [ 9.0934e-02, -6.5875e-01,  1.0438e+00,  ..., -5.0713e-01,\n",
       "           -8.7289e-01,  2.1795e-01],\n",
       "          [-1.8356e-01, -1.1961e+00,  2.2963e-01,  ...,  7.3657e-01,\n",
       "           -2.2857e-01,  2.7043e-01]],\n",
       "\n",
       "         [[ 5.6963e-01,  2.7812e-01, -1.6147e-01,  ...,  1.2655e-01,\n",
       "           -1.4868e-02, -1.9893e-01],\n",
       "          [-8.8545e-01, -1.9208e-01, -5.9129e-01,  ..., -8.3581e-01,\n",
       "           -2.0656e-01,  5.7632e-01],\n",
       "          [-2.4071e-01, -6.0673e-01, -1.8706e-01,  ..., -9.5231e-01,\n",
       "            1.3738e+00, -8.6729e-01],\n",
       "          ...,\n",
       "          [ 1.0481e-01,  7.1717e-01, -3.8661e-01,  ...,  8.7719e-01,\n",
       "           -4.2652e-01, -1.9714e-01],\n",
       "          [ 2.0701e+00,  8.8800e-01,  6.1528e-01,  ...,  2.4187e-01,\n",
       "           -3.2291e-01, -5.1530e-01],\n",
       "          [ 4.6262e-01, -8.6698e-01,  1.4780e+00,  ...,  5.8846e-01,\n",
       "           -1.7087e-01,  4.1503e-01]],\n",
       "\n",
       "         [[-1.1193e-01, -3.8027e-01,  3.8982e-01,  ...,  5.3510e-01,\n",
       "            4.4060e-01,  3.2058e-01],\n",
       "          [-5.8800e-01,  8.7464e-01, -3.1725e-01,  ...,  9.1892e-01,\n",
       "            4.2034e-01, -1.4445e+00],\n",
       "          [-3.4993e-01, -2.4721e-01, -3.2502e-03,  ..., -4.7888e-01,\n",
       "            1.0499e-01, -3.1730e-01],\n",
       "          ...,\n",
       "          [-6.8282e-01, -2.3137e-01, -9.1536e-01,  ...,  4.0988e-01,\n",
       "           -2.1729e-01, -4.0591e-01],\n",
       "          [-2.5102e-01,  2.5199e-01, -4.3067e-01,  ..., -1.0805e-01,\n",
       "           -5.6554e-02, -1.9522e-01],\n",
       "          [-1.7059e+00,  2.8517e-01,  7.7909e-01,  ..., -1.1103e+00,\n",
       "           -1.8749e-01,  3.3102e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-8.3928e-01,  4.4333e-02, -1.9723e-01,  ..., -1.9269e-01,\n",
       "            2.7665e-01, -4.6504e-01],\n",
       "          [ 1.4116e-01, -5.8943e-02, -7.4361e-01,  ..., -6.7742e-02,\n",
       "            9.4226e-01,  3.6009e-01],\n",
       "          [-6.9266e-01,  2.1160e-01, -2.0255e-01,  ..., -3.8467e-01,\n",
       "           -1.0530e+00,  1.1286e-01],\n",
       "          ...,\n",
       "          [-2.1583e-01,  8.0934e-02,  5.6942e-01,  ..., -4.0704e-01,\n",
       "           -8.6068e-01, -5.6826e-01],\n",
       "          [ 1.1738e+00,  6.9856e-01, -1.8261e-01,  ...,  8.0613e-02,\n",
       "           -2.7826e-01,  1.0088e+00],\n",
       "          [ 4.5999e-01,  2.1713e-01, -2.8321e-01,  ..., -7.2358e-01,\n",
       "            4.9614e-01,  1.8231e-01]],\n",
       "\n",
       "         [[ 9.6247e-01, -3.6793e-01,  6.1198e-01,  ..., -1.5493e-01,\n",
       "            7.4162e-01, -3.5179e-01],\n",
       "          [-3.4602e-01, -9.0980e-01, -4.2633e-01,  ...,  3.2634e-01,\n",
       "           -5.5684e-01, -2.8288e-01],\n",
       "          [ 1.3204e+00, -7.7075e-03, -2.0329e-01,  ..., -5.7234e-01,\n",
       "           -2.9722e-01, -3.4943e-02],\n",
       "          ...,\n",
       "          [ 1.0520e+00,  4.8715e-02,  7.0868e-01,  ...,  8.2401e-02,\n",
       "            8.5376e-01,  5.5472e-01],\n",
       "          [-9.6671e-01, -1.7778e-01,  7.0157e-01,  ...,  1.3467e-01,\n",
       "           -9.3404e-01,  3.7812e-02],\n",
       "          [-3.1876e-01,  9.7735e-01,  1.9868e-01,  ..., -1.4299e-01,\n",
       "           -5.0098e-01,  5.9222e-01]],\n",
       "\n",
       "         [[-6.7344e-01,  4.4759e-01, -6.3041e-02,  ..., -2.6567e-01,\n",
       "            2.5943e-01, -2.3297e-01],\n",
       "          [-4.1118e-02,  8.9648e-01, -4.7386e-01,  ..., -1.3799e-02,\n",
       "           -2.7636e-01, -1.1544e+00],\n",
       "          [ 1.9753e-01,  1.4455e+00, -6.1492e-01,  ...,  1.6646e-01,\n",
       "            5.5824e-01,  9.0589e-02],\n",
       "          ...,\n",
       "          [-8.9729e-02,  4.3720e-01, -5.3580e-01,  ..., -4.5998e-01,\n",
       "           -1.1604e-01, -8.0194e-01],\n",
       "          [ 5.3951e-01,  7.2864e-01, -5.9816e-01,  ..., -6.8127e-02,\n",
       "            5.9286e-01, -1.9189e-01],\n",
       "          [-4.0218e-01,  5.8223e-01, -1.7588e-01,  ...,  4.6687e-01,\n",
       "            3.2695e-01,  2.3423e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 6.6208e-01,  3.7253e-01,  7.1210e-01,  ...,  5.4388e-01,\n",
       "            1.0567e+00, -2.1183e-01],\n",
       "          [-6.5934e-01, -3.4513e-02,  4.3195e-02,  ..., -3.1262e-01,\n",
       "           -2.1891e-01, -2.5913e-01],\n",
       "          [-3.3889e-01,  8.3886e-01,  3.1737e-04,  ...,  1.1073e-01,\n",
       "           -4.7586e-01, -1.1553e+00],\n",
       "          ...,\n",
       "          [-1.1011e+00, -1.4062e-01, -6.0451e-01,  ..., -1.5969e-01,\n",
       "           -1.1897e+00,  1.9168e-01],\n",
       "          [-8.0748e-01,  3.3852e-01,  8.2157e-01,  ..., -4.0851e-01,\n",
       "           -5.5833e-02,  3.3327e-01],\n",
       "          [-2.8878e-01, -8.7183e-02, -1.6400e-01,  ..., -9.2535e-01,\n",
       "           -2.2799e-01, -3.8875e-01]],\n",
       "\n",
       "         [[-1.6558e-01,  3.1775e-01,  2.4080e-02,  ...,  1.1013e+00,\n",
       "           -2.9165e-01, -1.1296e+00],\n",
       "          [-7.6365e-01, -8.9520e-01, -6.5734e-01,  ...,  1.4388e-01,\n",
       "           -1.6077e-01, -4.3778e-01],\n",
       "          [-2.3196e-01, -1.2828e+00, -1.8682e-01,  ...,  6.8717e-02,\n",
       "            2.8618e-01,  9.2493e-03],\n",
       "          ...,\n",
       "          [ 3.3145e-01,  3.6239e-01, -5.5310e-01,  ..., -9.1643e-01,\n",
       "            6.9364e-01,  8.0079e-02],\n",
       "          [ 2.4237e-01,  2.5524e-01, -2.0658e-01,  ...,  6.9644e-01,\n",
       "            1.0970e-01,  1.5545e-01],\n",
       "          [-5.9517e-01,  3.5131e-01, -1.6519e+00,  ..., -5.5073e-02,\n",
       "           -3.3674e-02,  8.1500e-01]],\n",
       "\n",
       "         [[ 5.2110e-01, -1.2106e-01,  1.9573e-02,  ..., -6.6314e-01,\n",
       "           -4.3316e-01,  6.9096e-01],\n",
       "          [ 4.4426e-01, -3.2246e-01, -1.1103e+00,  ...,  3.9013e-01,\n",
       "            1.2168e-01,  3.2243e-01],\n",
       "          [-6.1596e-02, -1.7325e-01, -3.7189e-01,  ..., -2.6372e-01,\n",
       "           -7.2147e-02, -6.0027e-01],\n",
       "          ...,\n",
       "          [-4.2377e-01, -1.4720e-01, -6.1961e-01,  ..., -1.1175e-01,\n",
       "           -1.0115e+00, -3.1611e-01],\n",
       "          [ 6.2478e-02,  6.1279e-02, -2.8522e-01,  ...,  4.6862e-01,\n",
       "            7.5975e-01,  1.5458e-01],\n",
       "          [-5.4016e-01,  7.1902e-01, -2.5530e-01,  ..., -4.0724e-02,\n",
       "            1.7532e-01, -3.5746e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.7678e-01,  1.0274e-01, -4.2254e-01,  ...,  6.9987e-02,\n",
       "           -4.7987e-01,  1.7699e-01],\n",
       "          [ 6.1096e-01, -8.2394e-01, -1.0679e+00,  ...,  2.8095e-01,\n",
       "           -4.8274e-01, -4.9749e-01],\n",
       "          [ 7.7491e-01, -5.1736e-01, -1.8866e-01,  ..., -3.1626e-01,\n",
       "           -2.4669e-01, -9.2689e-01],\n",
       "          ...,\n",
       "          [-7.5708e-01,  4.2476e-01, -3.6206e-01,  ..., -9.6981e-01,\n",
       "           -4.5386e-02,  5.5862e-02],\n",
       "          [-4.3904e-01,  5.5136e-01, -1.4872e+00,  ..., -1.4795e+00,\n",
       "            6.3985e-02,  2.6045e-01],\n",
       "          [ 1.7681e-01,  5.0185e-01,  7.6175e-01,  ..., -2.3595e-01,\n",
       "            1.0951e-01, -4.3202e-01]],\n",
       "\n",
       "         [[ 1.0031e+00, -3.0124e-01,  1.5396e-01,  ...,  1.2740e-01,\n",
       "           -4.3274e-01,  6.1174e-01],\n",
       "          [ 1.0104e+00, -2.2547e-01,  8.4255e-01,  ...,  2.5642e-01,\n",
       "            5.9741e-02,  1.4813e-01],\n",
       "          [-4.6928e-01,  1.2026e-01,  6.4443e-01,  ..., -1.1533e+00,\n",
       "           -2.6515e-03,  3.1371e-01],\n",
       "          ...,\n",
       "          [ 2.7603e-01,  1.0594e-01,  1.2444e+00,  ..., -5.2540e-01,\n",
       "           -9.6849e-01, -1.3750e-01],\n",
       "          [-2.6227e-01,  3.2931e-01, -3.3510e-01,  ...,  3.0978e-01,\n",
       "            7.1318e-01, -6.3212e-01],\n",
       "          [ 4.5006e-01,  1.3833e-01, -5.9788e-01,  ..., -1.3166e-01,\n",
       "            1.9544e-01,  4.0746e-02]],\n",
       "\n",
       "         [[-4.2289e-01,  2.3182e-01,  4.2432e-01,  ...,  3.8704e-01,\n",
       "            8.0840e-01, -1.4765e-01],\n",
       "          [-4.4688e-01,  3.8879e-01, -3.4514e-01,  ..., -3.6261e-01,\n",
       "           -8.3985e-01, -5.2555e-01],\n",
       "          [ 6.5703e-02,  6.4046e-01, -5.3170e-01,  ...,  4.3856e-01,\n",
       "            3.1421e-01,  4.2995e-01],\n",
       "          ...,\n",
       "          [-2.4970e-01,  2.7959e-01, -5.5239e-01,  ...,  8.8946e-02,\n",
       "            1.0945e+00,  3.7549e-01],\n",
       "          [ 5.9922e-01, -5.8475e-01, -5.9886e-01,  ..., -2.4718e-01,\n",
       "           -5.2279e-01,  7.0509e-01],\n",
       "          [ 4.8725e-01,  3.6654e-01,  6.5161e-01,  ...,  1.0877e+00,\n",
       "            1.6240e-01,  7.4367e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.8433e-03,  7.1529e-01, -1.6954e+00,  ...,  1.7721e-01,\n",
       "            4.3265e-01,  7.1513e-01],\n",
       "          [-1.8711e-01,  2.0799e-01,  6.5851e-02,  ..., -5.6589e-01,\n",
       "            4.9827e-01, -6.0680e-01],\n",
       "          [ 3.8792e-01, -1.0660e+00,  9.8399e-01,  ..., -3.9897e-01,\n",
       "            4.9639e-01, -9.6675e-01],\n",
       "          ...,\n",
       "          [ 6.5399e-01, -2.1176e-01, -8.1536e-01,  ...,  3.1515e-01,\n",
       "           -4.7573e-01,  2.3913e-01],\n",
       "          [-2.1242e-01, -1.9702e-01, -5.6208e-01,  ...,  6.9988e-01,\n",
       "            2.2796e-02,  3.6701e-01],\n",
       "          [ 7.3250e-01,  2.4055e-01, -3.0705e-02,  ...,  2.1904e-02,\n",
       "           -2.6620e-02, -6.1811e-01]],\n",
       "\n",
       "         [[-4.3005e-03,  3.3682e-01,  2.5812e-01,  ..., -6.1139e-01,\n",
       "           -4.9303e-01,  6.9791e-01],\n",
       "          [ 4.6927e-01,  2.6400e-01, -2.1705e-01,  ...,  2.0410e-01,\n",
       "            2.3366e-01,  1.0104e-01],\n",
       "          [ 7.1275e-01,  3.1346e-03, -4.2451e-01,  ..., -3.2717e-01,\n",
       "           -9.7718e-01,  2.8686e-01],\n",
       "          ...,\n",
       "          [-1.0409e+00, -1.6218e-01, -1.6214e-01,  ...,  6.2914e-01,\n",
       "            4.2507e-01,  7.7128e-01],\n",
       "          [ 9.3517e-01,  2.1588e-01,  4.8448e-01,  ...,  4.7422e-01,\n",
       "           -1.5988e-01,  8.5603e-01],\n",
       "          [ 2.6883e-02, -4.1927e-01,  6.7834e-01,  ...,  6.2603e-01,\n",
       "            5.4772e-01, -6.4774e-01]],\n",
       "\n",
       "         [[ 4.5215e-01,  6.5697e-01, -6.7268e-01,  ...,  1.6210e-01,\n",
       "           -5.1247e-01,  3.9827e-01],\n",
       "          [-2.5121e-01, -7.7512e-02,  3.0375e-01,  ...,  5.5987e-01,\n",
       "            4.3678e-01,  1.2383e-02],\n",
       "          [-5.4639e-01, -2.8502e-01,  5.0833e-01,  ...,  1.2563e-01,\n",
       "           -1.3200e+00, -7.0821e-02],\n",
       "          ...,\n",
       "          [-5.0899e-01, -3.8509e-01,  5.9721e-02,  ..., -9.3594e-02,\n",
       "            1.3709e-01,  4.2863e-01],\n",
       "          [-5.8006e-01, -2.5909e-01,  1.5115e-01,  ...,  4.1373e-02,\n",
       "           -3.8256e-01, -3.9676e-01],\n",
       "          [ 1.0577e+00,  9.9232e-01, -5.4153e-01,  ...,  9.5311e-03,\n",
       "            3.7765e-01, -1.0127e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.0163e-02,  1.1911e-01, -2.2257e-01,  ...,  7.0828e-02,\n",
       "           -4.7112e-02, -1.6861e-02],\n",
       "          [-9.2118e-01, -1.4102e-01, -2.5683e-01,  ..., -1.6902e-01,\n",
       "           -1.0931e+00,  6.9750e-01],\n",
       "          [-7.9837e-01, -8.2650e-02, -1.5480e-01,  ..., -8.2290e-01,\n",
       "           -7.5987e-01,  2.6956e-01],\n",
       "          ...,\n",
       "          [-8.3494e-01,  1.2011e-01,  9.1873e-02,  ...,  1.0761e-01,\n",
       "            8.4393e-02, -5.2261e-02],\n",
       "          [-5.0921e-01,  4.9280e-01, -1.1536e-01,  ...,  9.9344e-01,\n",
       "           -1.0999e+00, -4.2279e-01],\n",
       "          [ 4.1831e-01,  5.9588e-01,  2.8609e-01,  ...,  1.5460e-01,\n",
       "           -1.0255e+00, -6.4386e-02]],\n",
       "\n",
       "         [[-3.1893e-01,  5.6756e-02,  2.4454e-01,  ..., -9.3817e-02,\n",
       "           -1.2667e-01, -1.1724e+00],\n",
       "          [-5.4586e-02, -3.1657e-01,  4.1617e-01,  ...,  6.2179e-01,\n",
       "            4.6545e-01, -9.0002e-02],\n",
       "          [ 1.2103e+00, -2.2492e-01, -3.4256e-01,  ..., -3.2523e-01,\n",
       "            6.0030e-01, -1.0086e+00],\n",
       "          ...,\n",
       "          [ 2.6493e-01,  9.8381e-01,  1.6638e-01,  ...,  1.3945e-01,\n",
       "            2.9107e-01, -3.6105e-01],\n",
       "          [-1.9640e-01, -6.2097e-02,  7.4398e-01,  ...,  2.3925e-02,\n",
       "            1.1630e+00,  6.5519e-02],\n",
       "          [-1.0785e+00,  2.4054e-01, -1.1617e-01,  ...,  8.5032e-01,\n",
       "           -1.4864e-01, -4.3244e-01]],\n",
       "\n",
       "         [[ 2.6535e-01,  4.8628e-01,  1.8011e-01,  ..., -1.2562e+00,\n",
       "            6.5253e-01,  7.4765e-02],\n",
       "          [ 2.1513e-01, -7.3162e-01,  3.7773e-01,  ...,  2.3631e-01,\n",
       "           -3.8225e-01,  3.9931e-01],\n",
       "          [-1.6102e-01,  2.1958e-01,  3.5501e-01,  ...,  6.6902e-01,\n",
       "            1.1216e-01,  7.7249e-01],\n",
       "          ...,\n",
       "          [-2.0362e-01,  4.5934e-01,  1.0733e+00,  ..., -3.6071e-01,\n",
       "           -2.7125e-01, -3.1713e-01],\n",
       "          [ 7.2854e-01, -2.2856e-02,  4.8297e-01,  ...,  3.0358e-01,\n",
       "            9.0397e-01,  3.0201e-01],\n",
       "          [-2.1402e-02,  5.4458e-01, -3.3023e-01,  ..., -2.4350e-01,\n",
       "            1.0161e-01, -9.6290e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.2867e+00,  1.0048e+00, -5.7197e-01,  ...,  1.9559e-01,\n",
       "           -5.9728e-01,  4.2605e-02],\n",
       "          [-3.2450e-01, -1.1371e+00,  9.5109e-01,  ..., -1.0036e+00,\n",
       "           -1.6193e-01, -1.0781e-01],\n",
       "          [-6.7069e-01, -5.8509e-01,  3.5640e-01,  ..., -2.3491e-01,\n",
       "            5.3441e-01,  4.1402e-02],\n",
       "          ...,\n",
       "          [-3.2292e-01, -6.7473e-02,  4.8274e-01,  ...,  7.2950e-01,\n",
       "           -2.9673e-01, -2.1875e-01],\n",
       "          [ 1.5944e-01,  2.5870e-01,  6.4454e-01,  ..., -8.3297e-01,\n",
       "            3.3557e-01, -4.2581e-02],\n",
       "          [ 7.4412e-02, -1.8146e-01, -5.6590e-01,  ...,  5.6112e-01,\n",
       "            2.4843e-01, -9.2194e-01]],\n",
       "\n",
       "         [[ 2.3530e-01,  9.2657e-02,  1.7627e-01,  ..., -7.9392e-01,\n",
       "            3.3013e-01, -2.6431e-02],\n",
       "          [ 5.3468e-01,  1.3230e+00, -7.6362e-01,  ...,  4.9787e-01,\n",
       "           -2.0291e-01,  2.8831e-01],\n",
       "          [ 2.2414e-01,  9.0456e-01, -1.4798e-01,  ..., -3.9008e-01,\n",
       "           -5.9716e-01,  3.9754e-01],\n",
       "          ...,\n",
       "          [-6.8251e-03, -7.7982e-02, -5.3952e-02,  ..., -2.4323e-01,\n",
       "            1.1206e+00,  5.3316e-01],\n",
       "          [ 4.0386e-02, -9.9048e-01,  6.3007e-01,  ..., -4.4068e-01,\n",
       "           -5.6505e-01,  6.8911e-01],\n",
       "          [-2.0416e-01,  3.3117e-02,  2.0355e-01,  ...,  2.1037e-01,\n",
       "            5.1293e-02,  4.1158e-01]],\n",
       "\n",
       "         [[ 1.6940e-01, -3.7600e-01,  9.2543e-02,  ...,  7.5094e-02,\n",
       "            3.9457e-01, -1.4792e+00],\n",
       "          [-1.4462e-01,  5.0471e-01, -6.1325e-01,  ...,  5.1983e-01,\n",
       "            5.6098e-01,  7.4262e-01],\n",
       "          [-6.2780e-01,  6.5409e-01,  7.2234e-01,  ..., -7.7708e-01,\n",
       "           -1.3343e-01, -1.4504e-01],\n",
       "          ...,\n",
       "          [ 2.4155e-01, -1.1672e+00, -2.4231e-01,  ...,  6.0036e-02,\n",
       "            5.0410e-02, -7.2833e-01],\n",
       "          [-1.0965e+00,  2.2174e-01,  3.2413e-01,  ..., -3.4838e-01,\n",
       "            1.1138e-01, -2.8699e-01],\n",
       "          [-3.4114e-02, -1.3291e-01, -3.7131e-01,  ...,  3.3417e-01,\n",
       "            9.9541e-03, -2.4313e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0034e+00, -9.1557e-01, -4.6876e-01,  ...,  1.2830e-01,\n",
       "           -4.4793e-01, -1.8137e-01],\n",
       "          [ 6.7187e-02, -1.6851e-01, -1.0923e+00,  ...,  3.1076e-01,\n",
       "           -1.5831e-01, -4.0716e-01],\n",
       "          [-8.4013e-01, -5.2652e-01,  1.3898e-01,  ...,  9.5136e-01,\n",
       "           -5.8201e-01, -2.2685e-01],\n",
       "          ...,\n",
       "          [ 3.1591e-01, -5.1926e-02, -4.2640e-01,  ..., -8.2680e-01,\n",
       "           -2.9091e-01,  1.6943e-02],\n",
       "          [ 4.0530e-01,  5.5834e-01, -5.7480e-01,  ...,  6.5399e-02,\n",
       "            5.5446e-01,  1.0534e-01],\n",
       "          [ 4.4500e-01, -3.0205e-02, -6.3942e-02,  ..., -3.6767e-01,\n",
       "           -9.0764e-01,  5.2432e-01]],\n",
       "\n",
       "         [[-7.1543e-01,  9.9755e-01, -1.7023e-02,  ..., -2.5142e-01,\n",
       "            4.4736e-01, -2.7220e-01],\n",
       "          [-1.3785e-01,  2.7648e-01,  1.4016e-01,  ...,  8.5150e-01,\n",
       "           -6.2070e-01,  7.7149e-01],\n",
       "          [ 1.1639e+00, -5.1051e-01, -2.5935e-01,  ...,  2.1146e-01,\n",
       "            1.1090e-02,  9.1174e-01],\n",
       "          ...,\n",
       "          [ 6.2484e-01,  3.7332e-01,  1.9136e-01,  ..., -3.0055e-01,\n",
       "            3.6115e-01,  2.9689e-01],\n",
       "          [ 1.6980e-01, -4.9583e-01, -1.1826e-01,  ...,  8.5288e-01,\n",
       "           -9.6124e-01,  4.8765e-02],\n",
       "          [-1.0867e+00,  6.4748e-01, -3.3259e-01,  ..., -2.1301e-01,\n",
       "            2.2464e-01,  5.2126e-02]],\n",
       "\n",
       "         [[ 7.9275e-01, -2.7348e-02,  7.1462e-01,  ..., -1.4647e-01,\n",
       "            1.0972e+00, -2.8425e-01],\n",
       "          [-7.9402e-01,  6.8940e-01, -5.9228e-01,  ...,  7.8574e-01,\n",
       "           -1.8933e-01, -7.6314e-01],\n",
       "          [-2.9177e-01, -5.4071e-01,  3.9776e-01,  ...,  5.3663e-02,\n",
       "            7.6367e-01, -7.5965e-01],\n",
       "          ...,\n",
       "          [-2.2441e-01, -6.0294e-01,  3.6724e-01,  ..., -2.0892e-02,\n",
       "            3.5951e-01,  1.8866e-01],\n",
       "          [ 4.7968e-01,  3.2627e-01,  2.4601e-01,  ...,  2.0862e-01,\n",
       "           -1.2726e-01,  2.6594e-02],\n",
       "          [ 2.5122e-01, -6.6873e-01,  6.4484e-02,  ..., -1.0698e-01,\n",
       "           -3.6013e-01,  7.9001e-01]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m out_torch\u001b[38;5;241m.\u001b[39mbackward(torch\u001b[38;5;241m.\u001b[39mones_like(o2))\n",
      "File \u001b[1;32mc:\\Users\\Camel\\miniconda3\\envs\\camillagrad\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    527\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Camel\\miniconda3\\envs\\camillagrad\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m _engine_run_backward(\n\u001b[0;32m    268\u001b[0m     tensors,\n\u001b[0;32m    269\u001b[0m     grad_tensors_,\n\u001b[0;32m    270\u001b[0m     retain_graph,\n\u001b[0;32m    271\u001b[0m     create_graph,\n\u001b[0;32m    272\u001b[0m     inputs,\n\u001b[0;32m    273\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Camel\\miniconda3\\envs\\camillagrad\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "out_torch.backward(torch.ones_like(o2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from tensor import Tensor\n",
    "#from BatchNorm import BatchNorm\n",
    "import torch\n",
    "\n",
    "N,C,H,W = 2,3,4,4\n",
    "\n",
    "img_t = np.random.randn(N,C,H,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor import Tensor\n",
    "img = Tensor(img_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed Tensor(data = [1. 1. 1.], grad = 0) Tensor(data = [0. 0. 0.], grad = 0)\n",
      "mu=Tensor(data = [[[[-0.03333687]]\n",
      "\n",
      "  [[ 0.23460513]]\n",
      "\n",
      "  [[ 0.18805282]]]], grad = 0)\n",
      "var=Tensor(data = [[[[1.15146756]]\n",
      "\n",
      "  [[1.0252791 ]]\n",
      "\n",
      "  [[0.81169145]]]], grad = 0)\n"
     ]
    }
   ],
   "source": [
    "#import numpy as np\n",
    "#from tensor import Tensor\n",
    "#from BatchNorm import BatchNorm\n",
    "#import torch\n",
    "bn = BatchNorm(num_feats =3)\n",
    "\n",
    "output = bn(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.9140,  1.5541, -0.4857,  2.6703],\n",
       "          [-2.2852,  1.3853, -0.3243, -0.2378],\n",
       "          [-0.2192, -0.7823,  0.6649,  1.4055],\n",
       "          [-0.9424,  0.1205,  1.0601,  0.1943]],\n",
       "\n",
       "         [[-2.1895,  1.3304,  0.2900,  1.7394],\n",
       "          [-1.4406,  1.4581,  0.2652,  1.5393],\n",
       "          [ 0.8078,  0.7346,  0.0826, -0.7826],\n",
       "          [ 0.5718, -0.0468, -0.2557, -0.6868]],\n",
       "\n",
       "         [[-1.3961,  0.9195,  0.5097,  0.0304],\n",
       "          [ 0.4641,  0.3996, -0.2782, -0.4890],\n",
       "          [ 0.3179, -2.0279, -0.0979,  1.3985],\n",
       "          [-0.9711, -0.2634,  0.6741, -0.4993]]],\n",
       "\n",
       "\n",
       "        [[[ 0.5729,  0.2872,  1.1061,  0.2904],\n",
       "          [ 1.0168, -0.1672, -0.8937,  0.3250],\n",
       "          [-1.0344, -0.4336, -0.7510, -1.4438],\n",
       "          [-0.8650,  0.1839, -0.5817, -0.4762]],\n",
       "\n",
       "         [[-0.2066,  1.9514, -1.1443, -0.3223],\n",
       "          [ 0.0250,  0.4032, -0.3078, -0.9256],\n",
       "          [ 1.2806, -1.2648,  0.1721, -0.7353],\n",
       "          [ 0.3961, -0.5908, -1.0195, -1.1288]],\n",
       "\n",
       "         [[ 1.5201,  0.4737,  0.7080, -0.1334],\n",
       "          [-2.8910, -1.3926,  1.4024,  0.0575],\n",
       "          [ 0.8429,  0.8665,  0.4317,  1.3654],\n",
       "          [-0.1066, -0.8162, -0.9142, -0.1051]]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(data = [[[[-0.91404941  1.55407748 -0.48567905  2.67030519]\n",
       "   [-2.28516359  1.38529931 -0.32425225 -0.23780134]\n",
       "   [-0.21917474 -0.78228564  0.66485396  1.40555334]\n",
       "   [-0.94235994  0.12052279  1.06012196  0.19431807]]\n",
       "\n",
       "  [[-2.18952801  1.33042274  0.29000338  1.73938283]\n",
       "   [-1.440597    1.45812202  0.26524198  1.53927624]\n",
       "   [ 0.80777575  0.73463695  0.08261354 -0.78256547]\n",
       "   [ 0.57178843 -0.04680691 -0.25566549 -0.68676729]]\n",
       "\n",
       "  [[-1.39612012  0.91947421  0.50968355  0.03040984]\n",
       "   [ 0.46413086  0.39958066 -0.27819866 -0.48899825]\n",
       "   [ 0.31787211 -2.02787866 -0.09788587  1.39852948]\n",
       "   [-0.97106082 -0.2633817   0.67413989 -0.49925895]]]\n",
       "\n",
       "\n",
       " [[[ 0.57287966  0.28719156  1.10611712  0.29036505]\n",
       "   [ 1.01681912 -0.16720352 -0.89368536  0.3250485 ]\n",
       "   [-1.03438784 -0.43360959 -0.75098362 -1.44383249]\n",
       "   [-0.86496118  0.18387678 -0.58171452 -0.47620583]]\n",
       "\n",
       "  [[-0.20660791  1.95139397 -1.14430445 -0.32228287]\n",
       "   [ 0.0249993   0.40320232 -0.30779812 -0.92555814]\n",
       "   [ 1.28056025 -1.26475854  0.17211605 -0.73531402]\n",
       "   [ 0.39606088 -0.59078303 -1.01947794 -1.12878143]]\n",
       "\n",
       "  [[ 1.52010534  0.47373606  0.70802506 -0.13340222]\n",
       "   [-2.89105774 -1.39264961  1.40236064  0.05748344]\n",
       "   [ 0.84289989  0.86651794  0.43173033  1.36538147]\n",
       "   [-0.10663994 -0.81618717 -0.91424539 -0.10509566]]]], grad = 0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_bn = torch.nn.BatchNorm2d(3, momentum=0.1, affine=False)\n",
    "out_torch = torch_bn(torch_img)\n",
    "#torch_bn.weight.data = torch.tensor(bn.gamma.data, dtype=torch.float)\n",
    "#torch_bn.bias.data = torch.tensor(bn.beta.data,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor import Tensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_torch_tensors(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tests():\n",
    "    # 1st arg: the function, rest is tensors\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor(np.array([[1,2,3],[4,5,6]]))\n",
    "b = Tensor(np.array([[1,4,5], [4,3,1]]))\n",
    "\n",
    "c=a+b\n",
    "\n",
    "e = Tensor(np.array([1,1,1]))\n",
    "f = a*e\n",
    "\n",
    "g = a/f\n",
    "\n",
    "h = g.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a_tenser = torch.tensor(a.data, dtype=float, requires_grad= True)\n",
    "b_tenser = torch.tensor(b.data, dtype=float, requires_grad= True)\n",
    "e_tenser = torch.tensor(e.data, dtype=float, requires_grad= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_tensor=a_tenser+b_tenser\n",
    "\n",
    "f_tenser = a_tenser*e_tenser\n",
    "a_tenser.retain_grad()\n",
    "f_tenser.retain_grad()\n",
    "g_tensor = a_tenser/f_tenser\n",
    "g_tensor.retain_grad()\n",
    "h_tenser = g_tensor.sum()\n",
    "h_tenser.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 4., 5.],\n",
      "        [4., 3., 1.]], dtype=torch.float64, grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "s = b_tenser.relu()\n",
    "print(s)\n",
    "o = s.sum()\n",
    "o.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = b.relu()\n",
    "o2 = s2.sum()\n",
    "o2.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.]], dtype=torch.float64),\n",
       " array([[1, 1, 1],\n",
       "        [1, 1, 1]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_tenser.grad, b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Tensor(np.array([[1,2,3],[4,5,6]]))\n",
    "y = Tensor(np.array([[1,2,3]]))\n",
    "z = Tensor(np.array([1,1,1]))\n",
    "a,b,c = x,y,z\n",
    "d = a+b # Broadcast\n",
    "d.retain_grad()\n",
    "e = a-b\n",
    "e.retain_grad()\n",
    "f = d*e\n",
    "f.retain_grad()\n",
    "g = f/c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tensor import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    x = Tensor(np.array([[1,2,3],[4,5,6]]))\n",
    "    y = Tensor(np.array([[1,2,3]]))\n",
    "    z = Tensor(np.array([1,1,1]))\n",
    "    a,b,c = x,y,z\n",
    "    d = a+b # Broadcast\n",
    "    d.retain_grad()\n",
    "    e = a-b\n",
    "    \n",
    "    e.retain_grad()\n",
    "    f = d*e\n",
    "    k = f.mean()\n",
    "    \n",
    "    k.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.33333333, 0.66666667, 1.        ],\n",
       "        [1.33333333, 1.66666667, 2.        ]]),\n",
       " array([-5., -5., -5.]),\n",
       " array([[0. , 0. , 0. ],\n",
       "        [0.5, 0.5, 0.5]]),\n",
       " array([[0.33333333, 0.66666667, 1.        ],\n",
       "        [0.83333333, 1.16666667, 1.5       ]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad, b.grad, d.grad, e.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.66666667, -1.33333333, -2.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.grad.sum(axis=0)  - e.grad.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5.6667e+00, 1.2333e+01, 1.7000e+01],\n",
       "         [4.3587e+06, 2.1980e+09, 1.0641e+12]], dtype=torch.float64),\n",
       " tensor([[-1.0897e+06, -8.7921e+08, -5.3205e+11]], dtype=torch.float64),\n",
       " tensor([[0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.5000]], dtype=torch.float64),\n",
       " tensor([[0.3333, 0.6667, 1.0000],\n",
       "         [0.8333, 1.1667, 1.5000]], dtype=torch.float64))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad, b.grad, d.grad, e.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "    a,b,c = x_t,y_t,z_t\n",
    "    d = a+b # Broadcast\n",
    "    d.retain_grad()\n",
    "    e = a-b\n",
    "    \n",
    "    e.retain_grad()\n",
    "    f = d*e\n",
    "    k = f.mean()\n",
    "    \n",
    "    k.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 0\n",
    "w+= np.array([0.33333333, 0.33333333, 0.33333333])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33333333, 0.33333333, 0.33333333])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.33588985, -1.87211256,  1.63406184])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0]) + np.random.randn(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.33333333e-01, 6.66666667e-01, 1.00000000e+00],\n",
       "       [2.72418114e+06, 1.53861836e+09, 7.98072361e+11]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0897e+06, -8.7921e+08, -5.3205e+11]], dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads_true1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(data = [[1 2 3]], grad = [[0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
       " [3.26901737e+06 1.31881573e+09 5.32048241e+11]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(data = [[0 0 0]\n",
      " [3 3 3]], grad = 0),\n",
      "f=Tensor(data = [[ 0  0  0]\n",
      " [15 21 27]], grad = 0),\n",
      "Tensor(data = [[ 0.  0.  0.]\n",
      " [15. 21. 27.]], grad = [[1.66666667e-01 1.66666667e-01 1.66666667e-01]\n",
      " [5.44836229e+05 2.19802622e+08 8.86747068e+10]]),\n",
      "h=Tensor(data = [[1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      " [3.26901737e+06 1.31881573e+09 5.32048241e+11]], grad = [[0.16666667 0.16666667 0.16666667]\n",
      " [0.16666667 0.16666667 0.16666667]])\n",
      ",i=Tensor(data = [[1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      " [3.26901737e+06 1.31881573e+09 5.32048241e+11]], grad = [[0.16666667 0.16666667 0.16666667]\n",
      " [0.16666667 0.16666667 0.16666667]])\n"
     ]
    }
   ],
   "source": [
    "print(f'{e},\\n{f=},\\n{g},\\n{h=}\\n,{i=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(data = [[1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      " [3.26901737e+06 1.31881573e+09 5.32048241e+11]], grad = 0)\n",
      "tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.2690e+06, 1.3188e+09, 5.3205e+11]], dtype=torch.float64,\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "softmax() received an invalid combination of arguments - got (), but expected one of:\n * (int dim, torch.dtype dtype)\n * (name dim, *, torch.dtype dtype)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 49\u001b[0m\n\u001b[0;32m     47\u001b[0m grads1 \u001b[38;5;241m=\u001b[39m perform_ops(x,y,z)\n\u001b[0;32m     48\u001b[0m grads2 \u001b[38;5;241m=\u001b[39m perform_ops2(x,x2)\n\u001b[1;32m---> 49\u001b[0m grads_true1 \u001b[38;5;241m=\u001b[39m perform_ops(x_t, y_t, z_t)\n\u001b[0;32m     50\u001b[0m grads_true2 \u001b[38;5;241m=\u001b[39m perform_ops2(x_t, x2_t)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_compare\u001b[39m():\n",
      "Cell \u001b[1;32mIn[14], line 29\u001b[0m, in \u001b[0;36mperform_ops\u001b[1;34m(a, b, c)\u001b[0m\n\u001b[0;32m     27\u001b[0m i\u001b[38;5;241m.\u001b[39mretain_grad()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m---> 29\u001b[0m j \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m.\u001b[39msoftmax()\n\u001b[0;32m     30\u001b[0m j\u001b[38;5;241m.\u001b[39mretain_grad()\n\u001b[0;32m     31\u001b[0m k \u001b[38;5;241m=\u001b[39m j\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[1;31mTypeError\u001b[0m: softmax() received an invalid combination of arguments - got (), but expected one of:\n * (int dim, torch.dtype dtype)\n * (name dim, *, torch.dtype dtype)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tensor import Tensor\n",
    "import numpy as np\n",
    "\n",
    "x = Tensor(np.array([[1,2,3],[4,5,6]]))\n",
    "y = Tensor(np.array([[1,2,3]]))\n",
    "z = Tensor(np.array([1,1,1]))\n",
    "x2 = Tensor(np.array([[2,3],[5,6],[7,8]]))\n",
    "\n",
    "x_t = torch.tensor(x.data, dtype=float, requires_grad=True)\n",
    "y_t = torch.tensor(y.data, dtype=float, requires_grad=True)\n",
    "z_t = torch.tensor(z.data, dtype=float, requires_grad=True)\n",
    "x2_t = torch.tensor(x2.data, dtype=float, requires_grad=True)\n",
    "\n",
    "def perform_ops(a,b,c):\n",
    "    d = a+b # Broadcast\n",
    "    d.retain_grad()\n",
    "    e = a-b\n",
    "    e.retain_grad()\n",
    "    f = d*e\n",
    "    f.retain_grad()\n",
    "    g = f/c\n",
    "    g.retain_grad()\n",
    "    h = g.exp()\n",
    "    h.retain_grad()\n",
    "    i = h.relu()\n",
    "    i.retain_grad()\n",
    "    print(i)\n",
    "    j = i.softmax()\n",
    "    j.retain_grad()\n",
    "    k = j.mean()\n",
    "    \n",
    "    k.backward()\n",
    "\n",
    "    return [a.grad, b.grad, c.grad, d.grad, e.grad, f.grad, g.grad, h.grad, i.grad, j.grad, k.grad]\n",
    "\n",
    "def perform_ops2(a,b):\n",
    "    c = a@b\n",
    "    c.retain_grad()\n",
    "    d = c**3\n",
    "    d.retain_grad()\n",
    "    e = d.sum()\n",
    "\n",
    "    e.backward()\n",
    "    return [a.grad, b.grad, c.grad, d.grad, e.grad]\n",
    "\n",
    "grads1 = perform_ops(x,y,z)\n",
    "grads2 = perform_ops2(x,x2)\n",
    "grads_true1 = perform_ops(x_t, y_t, z_t)\n",
    "grads_true2 = perform_ops2(x_t, x2_t)\n",
    "\n",
    "\n",
    "def test_compare():\n",
    "    for i,j in zip(grads1, grads_true1):\n",
    "        try:\n",
    "           assert np.allclose(i, j.detach().numpy())\n",
    "        except:\n",
    "            assert j == None\n",
    "    for i,j in zip(grads2, grads_true2):\n",
    "        try:\n",
    "           assert np.allclose(i, j.detach().numpy())\n",
    "        except:\n",
    "            assert j == None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.data.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = Tensor(np.array([[1,2,3],[4,5,6]]))\n",
    "s = x.softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.backward(np.random.randn(x.shape[0], x.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m m \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m      2\u001b[0m m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "m = x.mean()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tensor import Tensor\n",
    "import numpy as np\n",
    "x = Tensor(np.array([[1,2,3],[4,5,6]]))\n",
    "y = Tensor(np.array([[1,2,3]]))\n",
    "z = Tensor(np.array([1,1,1]))\n",
    "x2 = Tensor(np.array([[2,3],[5,6],[7,8]]))\n",
    "\n",
    "def perform_ops(a,b,c):\n",
    "    d = a+b # Broadcast\n",
    "    d.retain_grad()\n",
    "    e = a-b\n",
    "    e.retain_grad()\n",
    "    f = d*e\n",
    "    f.retain_grad()\n",
    "    g = f/c\n",
    "    g.retain_grad()\n",
    "    h = g.exp()\n",
    "    h.retain_grad()\n",
    "    i = h.relu()\n",
    "    i.retain_grad()\n",
    "    #j = i.softmax()\n",
    "    #j.retain_grad()\n",
    "    k = i.mean()\n",
    "    \n",
    "    k.backward()\n",
    "\n",
    "    return [a.grad, b.grad, c.grad, d.grad, e.grad, f.grad, g.grad, h.grad, i.grad, k.grad]\n",
    "\n",
    "def perform_ops2(a,b):\n",
    "    c = a@b\n",
    "    c.retain_grad()\n",
    "    d = c.sum()\n",
    "\n",
    "    d.backward()\n",
    "    return [a.grad, b.grad, c.grad, d.grad]\n",
    "\n",
    "\n",
    "def compare(grads, torch_grads):\n",
    "    for i,j in zip(grads, torch_grads):\n",
    "        try:\n",
    "           assert np.allclose(i, j.detach().numpy())\n",
    "        except:\n",
    "            assert j == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t = torch.tensor(x.data, dtype=float, requires_grad=True)\n",
    "y_t = torch.tensor(y.data, dtype=float, requires_grad=True)\n",
    "z_t = torch.tensor(z.data, dtype=float, requires_grad=True)\n",
    "x2_t = torch.tensor(x2.data, dtype=float, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(grads1, grads_true1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(grads2, grads_true2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads1[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Camel\\AppData\\Local\\Temp\\ipykernel_14652\\4122796782.py:28: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten\\src\\ATen/core/TensorBody.h:494.)\n",
      "  return [a.grad, b.grad, c.grad, d.grad, e.grad, f.grad, g.grad, h.grad, i.grad, k.grad]\n",
      "C:\\Users\\Camel\\AppData\\Local\\Temp\\ipykernel_14652\\4122796782.py:36: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten\\src\\ATen/core/TensorBody.h:494.)\n",
      "  return [a.grad, b.grad, c.grad, d.grad]\n"
     ]
    }
   ],
   "source": [
    "grads1 = perform_ops(x,y,z)\n",
    "grads2 = perform_ops2(x,x2)\n",
    "grads_true1 = perform_ops(x_t, y_t, z_t)\n",
    "grads_true2 = perform_ops2(x_t, x2_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.72418148e+06, 1.53861836e+09, 7.98072361e+11])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.grad.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1089672.79"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-2.72418148e+06+1.63450869e+06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.63450869e+06, 6.59407867e+08, 2.66024120e+11]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[5.33333333e+00, 1.16666667e+01, 1.60000000e+01],\n",
       "        [4.35869483e+06, 2.19802624e+09, 1.06409648e+12]]),\n",
       " array([[-1.08967279e+06, -8.79210490e+08, -5.32048241e+11]]),\n",
       " array([-8.17254343e+06, -4.61585507e+09, -2.39421708e+12]),\n",
       " array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [1.63450869e+06, 6.59407867e+08, 2.66024120e+11]]),\n",
       " array([[3.33333333e-01, 6.66666667e-01, 1.00000000e+00],\n",
       "        [2.72418114e+06, 1.53861836e+09, 7.98072361e+11]]),\n",
       " array([[1.66666667e-01, 1.66666667e-01, 1.66666667e-01],\n",
       "        [5.44836229e+05, 2.19802622e+08, 8.86747068e+10]]),\n",
       " array([[1.66666667e-01, 1.66666667e-01, 1.66666667e-01],\n",
       "        [5.44836229e+05, 2.19802622e+08, 8.86747068e+10]]),\n",
       " array([[0.16666667, 0.16666667, 0.16666667],\n",
       "        [0.16666667, 0.16666667, 0.16666667]]),\n",
       " array([[0.16666667, 0.16666667, 0.16666667],\n",
       "        [0.16666667, 0.16666667, 0.16666667]]),\n",
       " array([1])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[5.3333e+00, 1.1667e+01, 1.6000e+01],\n",
       "         [4.3587e+06, 2.1980e+09, 1.0641e+12]], dtype=torch.float64),\n",
       " tensor([[-1.0897e+06, -8.7921e+08, -5.3205e+11]], dtype=torch.float64),\n",
       " tensor([-8.1725e+06, -4.6159e+09, -2.3942e+12], dtype=torch.float64),\n",
       " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [1.6345e+06, 6.5941e+08, 2.6602e+11]], dtype=torch.float64),\n",
       " tensor([[3.3333e-01, 6.6667e-01, 1.0000e+00],\n",
       "         [2.7242e+06, 1.5386e+09, 7.9807e+11]], dtype=torch.float64),\n",
       " tensor([[1.6667e-01, 1.6667e-01, 1.6667e-01],\n",
       "         [5.4484e+05, 2.1980e+08, 8.8675e+10]], dtype=torch.float64),\n",
       " tensor([[1.6667e-01, 1.6667e-01, 1.6667e-01],\n",
       "         [5.4484e+05, 2.1980e+08, 8.8675e+10]], dtype=torch.float64),\n",
       " tensor([[0.1667, 0.1667, 0.1667],\n",
       "         [0.1667, 0.1667, 0.1667]], dtype=torch.float64),\n",
       " tensor([[0.1667, 0.1667, 0.1667],\n",
       "         [0.1667, 0.1667, 0.1667]], dtype=torch.float64),\n",
       " None]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads_true1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[5.33333333e+00, 1.16666667e+01, 1.60000000e+01],\n",
       "        [4.35869483e+06, 2.19802624e+09, 1.06409648e+12]]),\n",
       " array([[5, 5],\n",
       "        [7, 7],\n",
       "        [9, 9]]),\n",
       " array([[1, 1],\n",
       "        [1, 1]]),\n",
       " array([1])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.33333333e-01, 6.66666667e-01, 1.00000000e+00],\n",
       "       [2.72418114e+06, 1.53861836e+09, 7.98072361e+11]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.66666667e-01, 1.66666667e-01, 1.66666667e-01],\n",
       "       [5.44836229e+05, 2.19802622e+08, 8.86747068e+10]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[5.3333e+00, 1.1667e+01, 1.6000e+01],\n",
       "         [4.3587e+06, 2.1980e+09, 1.0641e+12]], dtype=torch.float64),\n",
       " tensor([[-1.0897e+06, -8.7921e+08, -5.3205e+11]], dtype=torch.float64),\n",
       " tensor([-8.1725e+06, -4.6159e+09, -2.3942e+12], dtype=torch.float64),\n",
       " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [1.6345e+06, 6.5941e+08, 2.6602e+11]], dtype=torch.float64),\n",
       " tensor([[3.3333e-01, 6.6667e-01, 1.0000e+00],\n",
       "         [2.7242e+06, 1.5386e+09, 7.9807e+11]], dtype=torch.float64),\n",
       " tensor([[1.6667e-01, 1.6667e-01, 1.6667e-01],\n",
       "         [5.4484e+05, 2.1980e+08, 8.8675e+10]], dtype=torch.float64),\n",
       " tensor([[1.6667e-01, 1.6667e-01, 1.6667e-01],\n",
       "         [5.4484e+05, 2.1980e+08, 8.8675e+10]], dtype=torch.float64),\n",
       " tensor([[0.1667, 0.1667, 0.1667],\n",
       "         [0.1667, 0.1667, 0.1667]], dtype=torch.float64),\n",
       " tensor([[0.1667, 0.1667, 0.1667],\n",
       "         [0.1667, 0.1667, 0.1667]], dtype=torch.float64),\n",
       " None]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads_true1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18., dtype=torch.float64, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_tenser.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(data = [[1 2 3]\n",
       " [4 5 6]], grad = [[-1.         -0.5        -0.33333333]\n",
       " [-0.25       -0.2        -0.16666667]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Camel\\AppData\\Local\\Temp\\ipykernel_7568\\2686631694.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten\\src\\ATen/core/TensorBody.h:494.)\n",
      "  h_tenser.grad\n"
     ]
    }
   ],
   "source": [
    "h_tenser.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        , -0.25      , -0.11111111],\n",
       "       [-0.0625    , -0.04      , -0.02777778]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000, -0.5000, -0.3333],\n",
       "        [-0.2500, -0.2000, -0.1667]], dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_tenser.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.]], dtype=torch.float64),\n",
       " array([[1., 1., 1.],\n",
       "        [1., 1., 1.]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_tensor.grad, g.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.        , 0.5       , 0.33333333],\n",
       "        [0.25      , 0.2       , 0.16666667]]),\n",
       " tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.]], dtype=torch.float64))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad, a_tenser.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AddBack\n",
      "[[0.16666667 0.16666667 0.16666667]\n",
      " [0.16666667 0.16666667 0.16666667]] [[0.16666667 0.16666667 0.16666667]\n",
      " [0.16666667 0.16666667 0.16666667]]\n",
      "[[0.16666667 0.16666667 0.16666667]\n",
      " [0.16666667 0.16666667 0.16666667]] [[0.16666667 0.16666667 0.16666667]\n",
      " [0.16666667 0.16666667 0.16666667]]\n"
     ]
    }
   ],
   "source": [
    "d = c.mean()\n",
    "d.backward()\n",
    "print(a.grad, b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.32514881e-05, 2.32514881e-05, 2.32514881e-05],\n",
       "       [2.32514881e-05, 2.32514881e-05, 2.32514881e-05]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02564103, 0.02564103, 0.02564103],\n",
       "       [0.02564103, 0.02564103, 0.02564103]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a_tensor = torch.tensor(a.data,dtype=float, requires_grad=True)\n",
    "b_tensor = torch.tensor(b.data,dtype=float, requires_grad=True)\n",
    "c_tensor = a_tensor+b_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tensor=  c_tensor.mean()\n",
    "d_tensor.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.5000, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(data = 6.5, grad = [1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1667, 0.1667, 0.1667],\n",
       "         [0.1667, 0.1667, 0.1667]], dtype=torch.float64),\n",
       " tensor([[0.1667, 0.1667, 0.1667],\n",
       "         [0.1667, 0.1667, 0.1667]], dtype=torch.float64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_tensor.grad, b_tensor.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 3, 4, 4), torch.Size([2, 3, 4, 4]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape, out_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch_img = torch.tensor(img_t, dtype=torch.float)\n",
    "torch_bn = torch.nn.BatchNorm2d(3)\n",
    "out_torch = torch_bn(torch_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.9140,  1.5541, -0.4857,  2.6703],\n",
       "          [-2.2852,  1.3853, -0.3243, -0.2378],\n",
       "          [-0.2192, -0.7823,  0.6649,  1.4055],\n",
       "          [-0.9424,  0.1205,  1.0601,  0.1943]],\n",
       "\n",
       "         [[-2.1895,  1.3304,  0.2900,  1.7394],\n",
       "          [-1.4406,  1.4581,  0.2652,  1.5393],\n",
       "          [ 0.8078,  0.7346,  0.0826, -0.7826],\n",
       "          [ 0.5718, -0.0468, -0.2557, -0.6868]],\n",
       "\n",
       "         [[-1.3961,  0.9195,  0.5097,  0.0304],\n",
       "          [ 0.4641,  0.3996, -0.2782, -0.4890],\n",
       "          [ 0.3179, -2.0279, -0.0979,  1.3985],\n",
       "          [-0.9711, -0.2634,  0.6741, -0.4993]]],\n",
       "\n",
       "\n",
       "        [[[ 0.5729,  0.2872,  1.1061,  0.2904],\n",
       "          [ 1.0168, -0.1672, -0.8937,  0.3250],\n",
       "          [-1.0344, -0.4336, -0.7510, -1.4438],\n",
       "          [-0.8650,  0.1839, -0.5817, -0.4762]],\n",
       "\n",
       "         [[-0.2066,  1.9514, -1.1443, -0.3223],\n",
       "          [ 0.0250,  0.4032, -0.3078, -0.9256],\n",
       "          [ 1.2806, -1.2648,  0.1721, -0.7353],\n",
       "          [ 0.3961, -0.5908, -1.0195, -1.1288]],\n",
       "\n",
       "         [[ 1.5201,  0.4737,  0.7080, -0.1334],\n",
       "          [-2.8910, -1.3926,  1.4024,  0.0575],\n",
       "          [ 0.8429,  0.8665,  0.4317,  1.3654],\n",
       "          [-0.1066, -0.8162, -0.9142, -0.1051]]]],\n",
       "       grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
